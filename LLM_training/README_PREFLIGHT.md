# üöÄ Safe Train - Sistema de Verifica√ß√£o Pr√©-Treino

Um sistema completo e autom√°tico que **verifica seu sistema antes de treinar** e **recomenda as melhores configura√ß√µes para evitar crashes**.

## O Problema

O treino pode crashar por:
- ‚ùå Mem√≥ria insuficiente
- ‚ùå Depend√™ncias faltando
- ‚ùå GPU n√£o detectada
- ‚ùå Configura√ß√£o inadequada
- ‚ùå Espa√ßo em disco insuficiente

## A Solu√ß√£o

### ‚úÖ Sistema de Verifica√ß√£o Autom√°tica

Antes de iniciar o treino, corra:

```bash
python3 scripts/preflight_check.py
```

Este script:
1. ‚úì Verifica Python, MLX, todas as depend√™ncias
2. ‚úì Detecta hardware (Apple Silicon, RAM, GPU)
3. ‚úì Valida dados de treino
4. ‚úì Testa carregamento de modelo
5. ‚úì Verifica espa√ßo em disco
6. ‚úì **Recomenda configura√ß√£o otimizada** para seu sistema

## Resultado

O script gera dois ficheiros:

```
checkpoints_qlora/
‚îú‚îÄ‚îÄ preflight_report.json       ‚Üê Relat√≥rio completo do diagn√≥stico
‚îî‚îÄ‚îÄ recommended_config.json     ‚Üê CONFIG OTIMIZADA PARA SEU SISTEMA
```

## Como Usar

### Passo 1: Diagn√≥stico do Sistema (2 minutos)

```bash
cd /Users/f.nuno/Desktop/chatbot_2.0/LLM_training
python3 scripts/preflight_check.py
```

**Output esperado:**
```
================================================================================
  PREFLIGHT CHECK - LLM TRAINING
================================================================================

>>> 1. VERIFICA√á√ÉO DE HARDWARE
  ‚úì Apple Silicon (M1/M2/M3) detectado
  ‚úì Mem√≥ria: 7.3 GB dispon√≠vel
  ‚úì CPU: 8 cores

>>> 2. VERIFICA√á√ÉO DE DEPEND√äNCIAS
  ‚úì MLX
  ‚úì MLX-LM
  ‚úì Transformers
  ...

>>> 3. VERIFICA√á√ÉO DE GPU
  ‚úì Metal GPU detectado e ativado

>>> 4. VERIFICA√á√ÉO DE DADOS
  ‚úì Ficheiro de treino: train_v3_final_complete.jsonl (848 amostras)
  ‚úì Ficheiro de valida√ß√£o: valid_v3_final_complete.jsonl (95 amostras)

>>> 5. VERIFICA√á√ÉO DE MODELO
  ‚úì Modelo base encontrado (3.8 GB)
  ‚úì Modelo carregado com sucesso

>>> 6. VERIFICA√á√ÉO DE ESPA√áO EM DISCO
  ‚úì Espa√ßo em disco suficiente (10.7 GB)

>>> 7. RECOMENDA√á√ÉO DE CONFIGURA√á√ÉO
  CONFIGURA√á√ÉO RECOMENDADA:
  ‚Ä¢ batch_size: 1
  ‚Ä¢ gradient_accumulation: 4
  ‚Ä¢ max_seq_length: 256
  ‚Ä¢ learning_rate: 0.0002
  ‚Ä¢ num_epochs: 3

  RAZ√ÉO: Mem√≥ria limitada (6-8 GB) - config reduzida

================================================================================
  RESUMO DO PREFLIGHT CHECK
================================================================================
  ‚úì Passou: 16
  ‚úó Falhou: 1 (espa√ßo em disco - n√£o cr√≠tico)
  ‚ö† Avisos: 2 (Python version, mem√≥ria)

‚úì Relat√≥rio salvo: checkpoints_qlora/preflight_report.json
‚úì Config salva: checkpoints_qlora/recommended_config.json
```

### Passo 2: Aplicar Configura√ß√£o Recomendada

Abrir o ficheiro gerado:

```bash
cat checkpoints_qlora/recommended_config.json
```

#### Op√ß√£o A: Via Notebook (RECOMENDADO)

```bash
jupyter notebook notebooks/mistral_qlora_training.ipynb
```

Procurar pela c√©lula "Configura√ß√£o do Treino" e atualizar:

```python
training_config = {
    "batch_size": 1,                    # ‚Üê DO recommended_config.json
    "gradient_accumulation": 4,         # ‚Üê DO recommended_config.json
    "max_seq_length": 256,              # ‚Üê DO recommended_config.json
    "learning_rate": 0.0002,            # ‚Üê DO recommended_config.json
    "num_epochs": 3,
    "warmup_steps": 50,
    "save_steps": 100,
    "eval_steps": 100,
    "log_steps": 10,
}
```

Depois corre as c√©lulas normalmente.

#### Op√ß√£o B: Via Script

```bash
nano scripts/train_qlora.py
```

Atualizar a se√ß√£o `training_config` (linhas ~53-65) com os valores do `recommended_config.json`.

### Passo 3: Iniciar Treino

**Via Notebook:**
```bash
jupyter notebook notebooks/mistral_qlora_training.ipynb
# Executar c√©lulas normalmente
```

**Via Script:**
```bash
python3 scripts/train_qlora.py
```

### Passo 4: Monitorar (Terminal Separada)

Enquanto o treino est√° em progresso, abra uma terminal **diferente**:

```bash
python3 scripts/monitor.py --refresh 5
```

Mostra em tempo real:
- Loss de treino e valida√ß√£o
- Uso de mem√≥ria
- Checkpoint atual
- ETA at√© conclus√£o

### Passo 5: Ap√≥s Treino

```bash
# Visualizar gr√°ficos de resultados
python3 scripts/visualization.py --report

# Testar modelo treinado
python3 scripts/inference_qlora.py "Qual foi a melhor classifica√ß√£o do Farense?"
```

---

## Configura√ß√µes Recomendadas por Hardware

### M1 Base (8GB RAM)
```json
{
  "batch_size": 2,
  "gradient_accumulation": 2,
  "max_seq_length": 512,
  "learning_rate": 0.0003
}
```

### M1 Pro (16GB RAM)
```json
{
  "batch_size": 4,
  "gradient_accumulation": 2,
  "max_seq_length": 512,
  "learning_rate": 0.0005
}
```

### M1 Max (32GB RAM)
```json
{
  "batch_size": 8,
  "gradient_accumulation": 1,
  "max_seq_length": 512,
  "learning_rate": 0.0005
}
```

### M1 com Pouca Mem√≥ria (< 6GB)
```json
{
  "batch_size": 1,
  "gradient_accumulation": 8,
  "max_seq_length": 128,
  "learning_rate": 0.0001
}
```

---

## O Que Cada Configura√ß√£o Significa

### batch_size
Quantas amostras processa de cada vez. Maior = mais mem√≥ria, mais r√°pido.
- `1` = Muito lento mas usa pouca mem√≥ria
- `2` = Equil√≠brio
- `4+` = R√°pido mas precisa muita mem√≥ria

### gradient_accumulation
Simula batch_size maior sem usar mais mem√≥ria. Acumula gradientes ao longo de v√°rios passos.
- Aumentar se der "Out of Memory"
- `batch_size=1, grad_accum=4` ‚âà `batch_size=4, grad_accum=1`

### max_seq_length
Comprimento m√°ximo de cada exemplo. Maior = mais contexto mas mais mem√≥ria.
- `128` = Muito curto
- `256` = Recomendado para mem√≥ria limitada
- `512` = Recomendado para mem√≥ria adequada

### learning_rate
Velocidade de aprendizagem do modelo. Maior = mais inst√°vel, mais r√°pido.
- `5e-4` = 0.0005 (taxa alta, risco de instabilidade)
- `3e-4` = 0.0003 (taxa m√©dia, recomendado)
- `1e-4` = 0.0001 (taxa baixa, converg√™ncia lenta)

### num_epochs
Quantas vezes passa pelos dados. 3 √© padr√£o.

### warmup_steps
Passos iniciais com learning rate gradualmente aumentada. Evita instabilidade no in√≠cio.

### save_steps / eval_steps
Frequ√™ncia de salvar checkpoints e avaliar modelo.

---

## Troubleshooting

### Erro: "Out of Memory"

1. Reduzir `batch_size`: `4 ‚Üí 2 ‚Üí 1`
2. Aumentar `gradient_accumulation`: `2 ‚Üí 4 ‚Üí 8`
3. Reduzir `max_seq_length`: `512 ‚Üí 256 ‚Üí 128`

Recomenda√ß√£o: aumentar `gradient_accumulation` primeiro (mais eficiente que reduzir batch_size)

### Erro: "Model not found" ou "Downloading"

Normal! Primeira execu√ß√£o descarrega ~3.8GB do Mistral-7B. Pode levar 5-10 minutos.

### Treino muito lento

1. Aumentar `batch_size` (se houver mem√≥ria)
2. Aumentar `learning_rate`
3. Reduzir `warmup_steps`

### Loss n√£o diminui ou fica inst√°vel

1. Aumentar `learning_rate` gradualmente (ex: 1e-4 ‚Üí 2e-4 ‚Üí 3e-4)
2. Aumentar `warmup_steps`
3. Validar dados: `python3 scripts/validate_jsonl.py data/train.jsonl`

### GPU n√£o est√° sendo usada

Corra: `python3 scripts/diagnose_qlora.py`

Se ver "Device: CPU" em vez de "Device: GPU":
1. Verificar instala√ß√£o MLX: `pip install mlx`
2. Estar em Mac M1/M2/M3
3. Fechar outras aplica√ß√µes pesadas

---

## Ficheiros Gerados

### Durante Preflight Check
```
checkpoints_qlora/
‚îú‚îÄ‚îÄ preflight_report.json
‚îÇ   ‚îî‚îÄ‚îÄ Relat√≥rio completo: hardware, depend√™ncias, dados, config
‚îî‚îÄ‚îÄ recommended_config.json
    ‚îî‚îÄ‚îÄ Valores otimizados para seu sistema (COPIAR DAQUI!)
```

### Durante Treino
```
checkpoints_qlora/
‚îú‚îÄ‚îÄ checkpoint_epoch_0_step_100/    # Checkpoints intermedi√°rios
‚îú‚îÄ‚îÄ checkpoint_epoch_0_step_200/
‚îú‚îÄ‚îÄ checkpoint_epoch_1_step_100/
‚îÇ   ...
‚îú‚îÄ‚îÄ adapters/                       # Melhor modelo encontrado
‚îú‚îÄ‚îÄ training_metrics.json           # M√©tricas detalhadas
‚îú‚îÄ‚îÄ training_metrics.csv            # CSV format
‚îú‚îÄ‚îÄ training_summary.json           # Resumo final
‚îú‚îÄ‚îÄ training_state.json             # Para resume se interromper
‚îî‚îÄ‚îÄ plots/                          # Gr√°ficos gerados
    ‚îú‚îÄ‚îÄ loss.png
    ‚îú‚îÄ‚îÄ learning_rate.png
    ‚îî‚îÄ‚îÄ memory_usage.png
```

---

## Workflow Visual

```
START
  ‚îÇ
  ‚îú‚îÄ‚Üí python3 scripts/preflight_check.py
  ‚îÇ     ‚îú‚îÄ Verifica tudo
  ‚îÇ     ‚îî‚îÄ Gera recommended_config.json
  ‚îÇ
  ‚îú‚îÄ‚Üí Editar notebook/script com valores recomendados
  ‚îÇ
  ‚îú‚îÄ‚Üí jupyter notebook mistral_qlora_training.ipynb
  ‚îÇ   ou
  ‚îÇ   python3 scripts/train_qlora.py
  ‚îÇ
  ‚îú‚îÄ [Terminal separada:]
  ‚îÇ   python3 scripts/monitor.py
  ‚îÇ
  ‚îú‚îÄ‚Üí Aguardar conclus√£o (2-3 horas)
  ‚îÇ     ‚îî‚îÄ Checkpoints salvos em checkpoints_qlora/
  ‚îÇ
  ‚îú‚îÄ‚Üí python3 scripts/visualization.py --report
  ‚îÇ     ‚îî‚îÄ Ver gr√°ficos de progresso
  ‚îÇ
  ‚îî‚îÄ‚Üí python3 scripts/inference_qlora.py "sua pergunta"
        ‚îî‚îÄ Testar modelo treinado
```

---

## D√∫vidas Frequentes

**P: Por que o preflight check falhou?**
R: Abra `checkpoints_qlora/preflight_report.json` para ver detalhes. Resolva os problemas indicados.

**P: Posso ignorar avisos (‚ö†)?**
R: Avisos s√£o informativos. Erros (‚úó) precisam ser resolvidos.

**P: A config recomendada pode estar errada?**
R: √â baseada em seu hardware real. Se der erro, reduzir batch_size ou aumentar gradient_accumulation.

**P: Preciso correr preflight check sempre?**
R: Recomendado apenas primeira vez ou se hardware mudar. Sistema √© est√°vel depois.

**P: Posso treinar v√°rios modelos em paralelo?**
R: N√£o. GPU Metal n√£o suporta bem. Um treino de cada vez.

**P: Como retomar treino interrompido?**
R: Simplesmente correr o treino novamente. Detecta checkpoint automaticamente de `training_state.json`.

**P: Onde est√£o os ficheiros de treino?**
R: Em `data/train_v3_final_complete.jsonl` e `data/valid_v3_final_complete.jsonl`.

**P: Qual √© a dura√ß√£o esperada do treino?**
R: ~2-3 horas em M1/M2 com 3 √©pocas. Varia com config.

---

## Pr√≥ximos Passos

1. **Correr preflight check:**
   ```bash
   python3 scripts/preflight_check.py
   ```

2. **Ver configura√ß√£o recomendada:**
   ```bash
   cat checkpoints_qlora/recommended_config.json
   ```

3. **Abrir notebook:**
   ```bash
   jupyter notebook notebooks/mistral_qlora_training.ipynb
   ```

4. **Atualizar valores de config** (se√ß√£o "Configura√ß√£o do Treino")

5. **Executar treino** (correr as c√©lulas)

6. **Monitorar em terminal separada:**
   ```bash
   python3 scripts/monitor.py --refresh 5
   ```

---

## Suporte

Se tiver problemas:

1. Verificar `checkpoints_qlora/preflight_report.json`
2. Ler se√ß√£o "Troubleshooting" acima
3. Consultar `docs/troubleshooting/QLORA_TROUBLESHOOTING.md`
4. Executar `python3 scripts/diagnose_qlora.py`

---

**Boa sorte com o treino!** üöÄ

Para detalhes t√©cnicos, ver `SAFE_TRAIN_QUICK_START.md`.
