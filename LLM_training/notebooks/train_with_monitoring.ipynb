{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLX_LM LoRA Training with Monitoring\n",
    "\n",
    "Training a model with LoRA using the mlx_lm CLI with real-time output monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SYSTEM INFORMATION\n",
      "======================================================================\n",
      "Python Version:     3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:51:49) [Clang 16.0.6 ]\n",
      "Python Executable:  /Users/f.nuno/miniforge3/bin/python\n",
      "\n",
      "Platform:           macOS-26.0.1-arm64-arm-64bit\n",
      "Machine Type:       arm64\n",
      "Processor:          arm\n",
      "Architecture:       64bit\n",
      "  Model Identifier: MacBookPro17,1\n",
      "  Chip: Apple M1\n",
      "  Memory: 16 GB\n",
      "\n",
      "Memory:\n",
      "  Total:            16.00 GB\n",
      "  Available:        9.16 GB\n",
      "  Used:             2.98 GB\n",
      "  Percent:          42.7%\n",
      "\n",
      "CPU:\n",
      "  Physical Cores:   8\n",
      "  Logical Cores:    8\n",
      "  CPU Frequency:    3204 MHz\n",
      "\n",
      "Disk (Root):\n",
      "  Total:            926.35 GB\n",
      "  Used:             15.66 GB\n",
      "  Free:             5.78 GB\n",
      "  Percent:          73.0%\n",
      "\n",
      "Current Directory:  /Users/f.nuno/Desktop/chatbot_2.0/LLM_training/notebooks\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# System Information\n",
    "import platform\n",
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SYSTEM INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Python info\n",
    "print(f\"Python Version:     {sys.version}\")\n",
    "print(f\"Python Executable:  {sys.executable}\")\n",
    "\n",
    "# Platform info\n",
    "print(f\"\\nPlatform:           {platform.platform()}\")\n",
    "print(f\"Machine Type:       {platform.machine()}\")\n",
    "print(f\"Processor:          {platform.processor()}\")\n",
    "print(f\"Architecture:       {platform.architecture()[0]}\")\n",
    "\n",
    "# System details\n",
    "try:\n",
    "    # Try to get system model (macOS specific)\n",
    "    result = subprocess.run(['system_profiler', 'SPHardwareDataType'], \n",
    "                          capture_output=True, text=True, timeout=5)\n",
    "    for line in result.stdout.split('\\n'):\n",
    "        if 'Model Identifier' in line or 'Chip' in line or 'Memory' in line:\n",
    "            print(f\"  {line.strip()}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Memory information\n",
    "memory = psutil.virtual_memory()\n",
    "print(f\"\\nMemory:\")\n",
    "print(f\"  Total:            {memory.total / (1024**3):.2f} GB\")\n",
    "print(f\"  Available:        {memory.available / (1024**3):.2f} GB\")\n",
    "print(f\"  Used:             {memory.used / (1024**3):.2f} GB\")\n",
    "print(f\"  Percent:          {memory.percent}%\")\n",
    "\n",
    "# CPU information\n",
    "print(f\"\\nCPU:\")\n",
    "print(f\"  Physical Cores:   {psutil.cpu_count(logical=False)}\")\n",
    "print(f\"  Logical Cores:    {psutil.cpu_count(logical=True)}\")\n",
    "print(f\"  CPU Frequency:    {psutil.cpu_freq().current:.0f} MHz\")\n",
    "\n",
    "# Disk information\n",
    "disk = psutil.disk_usage('/')\n",
    "print(f\"\\nDisk (Root):\")\n",
    "print(f\"  Total:            {disk.total / (1024**3):.2f} GB\")\n",
    "print(f\"  Used:             {disk.used / (1024**3):.2f} GB\")\n",
    "print(f\"  Free:             {disk.free / (1024**3):.2f} GB\")\n",
    "print(f\"  Percent:          {disk.percent}%\")\n",
    "\n",
    "print(f\"\\nCurrent Directory:  {os.getcwd()}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root:       /Users/f.nuno/Desktop/chatbot_2.0/LLM_training\n",
      "Data Directory:     /Users/f.nuno/Desktop/chatbot_2.0/LLM_training/data\n",
      "Checkpoint Dir:     /Users/f.nuno/Desktop/chatbot_2.0/LLM_training/checkpoints\n",
      "Model Path:         /Users/f.nuno/Desktop/chatbot_2.0/LLM_training/models/mistral-7b-4bit\n",
      "\\nData directory exists: True\n",
      "Model directory exists: True\n"
     ]
    }
   ],
   "source": [
    "# Define paths and configuration\n",
    "project_root = Path(\"/Users/f.nuno/Desktop/chatbot_2.0/LLM_training\")\n",
    "data_dir = project_root / \"data\"\n",
    "checkpoint_dir = project_root / \"checkpoints\"\n",
    "checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "model_path = project_root / \"models/mistral-7b-4bit\"\n",
    "\n",
    "print(f\"Project Root:       {project_root}\")\n",
    "print(f\"Data Directory:     {data_dir}\")\n",
    "print(f\"Checkpoint Dir:     {checkpoint_dir}\")\n",
    "print(f\"Model Path:         {model_path}\")\n",
    "print(f\"\\\\nData directory exists: {data_dir.exists()}\")\n",
    "print(f\"Model directory exists: {model_path.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING PARAMETERS\n",
      "======================================================================\n",
      "Batch Size:         4\n",
      "Iterations:         100\n",
      "Learning Rate:      1e-05\n",
      "LoRA Layers:        4\n",
      "Max Seq Length:     2100\n",
      "Adapter Path:       /Users/f.nuno/Desktop/chatbot_2.0/LLM_training/checkpoints/adapters\n",
      "Validation Batches: 25\n",
      "Validation Interval: 100\n",
      "Save Every:         100\n",
      "Seed:               0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define training parameters\n",
    "batch_size = 4\n",
    "iters = 100\n",
    "learning_rate = 1e-5\n",
    "lora_layers = 4\n",
    "max_seq_length = 2100\n",
    "adapter_path = str(checkpoint_dir / \"adapters\")\n",
    "val_batches = 25\n",
    "val_interval = 100\n",
    "save_every = 100\n",
    "seed = 0\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING PARAMETERS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Batch Size:         {batch_size}\")\n",
    "print(f\"Iterations:         {iters}\")\n",
    "print(f\"Learning Rate:      {learning_rate}\")\n",
    "print(f\"LoRA Layers:        {lora_layers}\")\n",
    "print(f\"Max Seq Length:     {max_seq_length}\")\n",
    "print(f\"Adapter Path:       {adapter_path}\")\n",
    "print(f\"Validation Batches: {val_batches}\")\n",
    "print(f\"Validation Interval: {val_interval}\")\n",
    "print(f\"Save Every:         {save_every}\")\n",
    "print(f\"Seed:               {seed}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n======================================================================\n",
      "TRAINING COMMAND\n",
      "======================================================================\n",
      "python -u -m mlx_lm lora --model /Users/f.nuno/Desktop/chatbot_2.0/LLM_training/models/mistral-7b-4bit --train --data /Users/f.nuno/Desktop/chatbot_2.0/LLM_training/data --batch-size 4 --iters 100 --learning-rate 1e-05 --num-layers 4 --max-seq-length 2100 --adapter-path /Users/f.nuno/Desktop/chatbot_2.0/LLM_training/checkpoints/adapters --val-batches 25 --steps-per-eval 100 --save-every 100 --seed 0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Construct the mlx_lm.lora CLI command\n",
    "command = [\n",
    "    \"python\", \"-u\", \"-m\", \"mlx_lm\", \"lora\",\n",
    "    \"--model\", str(model_path),\n",
    "    \"--train\",\n",
    "    \"--data\", str(data_dir),\n",
    "    \"--batch-size\", str(batch_size),\n",
    "    \"--iters\", str(iters),\n",
    "    \"--learning-rate\", str(learning_rate),\n",
    "    \"--num-layers\", str(lora_layers),\n",
    "    \"--max-seq-length\", str(max_seq_length),\n",
    "    \"--adapter-path\", adapter_path,\n",
    "    \"--val-batches\", str(val_batches),\n",
    "    \"--steps-per-eval\", str(val_interval),\n",
    "    \"--save-every\", str(save_every),\n",
    "    \"--seed\", str(seed),\n",
    "]\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMMAND\")\n",
    "print(\"=\"*70)\n",
    "print(\" \".join(command))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n======================================================================\n",
      "STARTING MLX_LM CLI TRAINING\n",
      "======================================================================\\n\n",
      "Loading pretrained model\n",
      "Loading datasets\n",
      "Training\n",
      "Trainable parameters: 0.036% (2.621M/7248.024M)\n",
      "Starting training..., iters: 100\n",
      "\n",
      "Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]\n",
      "Calculating loss...:   4%|▍         | 1/25 [00:15<06:03, 15.16s/it]\n",
      "Calculating loss...:   8%|▊         | 2/25 [00:30<05:45, 15.01s/it]\n",
      "Calculating loss...:  12%|█▏        | 3/25 [00:44<05:29, 14.96s/it]\n",
      "Calculating loss...:  16%|█▌        | 4/25 [00:59<05:13, 14.93s/it]\n",
      "Calculating loss...:  20%|██        | 5/25 [01:14<04:58, 14.92s/it]\n",
      "Calculating loss...:  24%|██▍       | 6/25 [01:29<04:43, 14.91s/it]\n",
      "Calculating loss...:  28%|██▊       | 7/25 [01:44<04:28, 14.90s/it]\n",
      "Calculating loss...:  32%|███▏      | 8/25 [01:59<04:13, 14.90s/it]\n",
      "Calculating loss...:  36%|███▌      | 9/25 [02:06<03:16, 12.31s/it]\n",
      "Calculating loss...:  40%|████      | 10/25 [02:20<03:16, 13.11s/it]\n",
      "Calculating loss...:  44%|████▍     | 11/25 [02:35<03:11, 13.65s/it]\n",
      "Calculating loss...:  48%|████▊     | 12/25 [02:50<03:02, 14.03s/it]\n",
      "Calculating loss...:  52%|█████▏    | 13/25 [03:05<02:51, 14.29s/it]\n",
      "Calculating loss...:  56%|█████▌    | 14/25 [03:20<02:39, 14.47s/it]\n",
      "Calculating loss...:  60%|██████    | 15/25 [04:38<05:35, 33.53s/it]\n",
      "Calculating loss...:  64%|██████▍   | 16/25 [04:49<04:02, 26.93s/it]\n",
      "Calculating loss...:  68%|██████▊   | 17/25 [05:04<03:06, 23.32s/it]\n",
      "Calculating loss...:  72%|███████▏  | 18/25 [05:19<02:25, 20.79s/it]\n",
      "Calculating loss...:  76%|███████▌  | 19/25 [05:29<01:45, 17.54s/it]\n",
      "Calculating loss...:  80%|████████  | 20/25 [05:44<01:23, 16.75s/it]\n",
      "Calculating loss...:  84%|████████▍ | 21/25 [05:59<01:04, 16.19s/it]\n",
      "Calculating loss...:  88%|████████▊ | 22/25 [06:14<00:47, 15.80s/it]\n",
      "Calculating loss...:  92%|█████████▏| 23/25 [06:29<00:31, 15.54s/it]\n",
      "Calculating loss...:  96%|█████████▌| 24/25 [06:44<00:15, 15.35s/it]\n",
      "Calculating loss...: 100%|██████████| 25/25 [06:59<00:00, 15.21s/it]\n",
      "Calculating loss...: 100%|██████████| 25/25 [06:59<00:00, 16.76s/it]\n",
      "Iter 1: Val loss 1.620, Val took 356.582s\n",
      "libc++abi: terminating due to uncaught exception of type std::runtime_error: [METAL] Command buffer execution failed: Insufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "/Users/f.nuno/miniforge3/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n",
      "\\n\\n❌ Error during MLX_LM CLI training: Command '['python', '-u', '-m', 'mlx_lm', 'lora', '--model', '/Users/f.nuno/Desktop/chatbot_2.0/LLM_training/models/mistral-7b-4bit', '--train', '--data', '/Users/f.nuno/Desktop/chatbot_2.0/LLM_training/data', '--batch-size', '4', '--iters', '100', '--learning-rate', '1e-05', '--num-layers', '4', '--max-seq-length', '2100', '--adapter-path', '/Users/f.nuno/Desktop/chatbot_2.0/LLM_training/checkpoints/adapters', '--val-batches', '25', '--steps-per-eval', '100', '--save-every', '100', '--seed', '0']' died with <Signals.SIGABRT: 6>.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['python', '-u', '-m', 'mlx_lm', 'lora', '--model', '/Users/f.nuno/Desktop/chatbot_2.0/LLM_training/models/mistral-7b-4bit', '--train', '--data', '/Users/f.nuno/Desktop/chatbot_2.0/LLM_training/data', '--batch-size', '4', '--iters', '100', '--learning-rate', '1e-05', '--num-layers', '4', '--max-seq-length', '2100', '--adapter-path', '/Users/f.nuno/Desktop/chatbot_2.0/LLM_training/checkpoints/adapters', '--val-batches', '25', '--steps-per-eval', '100', '--save-every', '100', '--seed', '0']' died with <Signals.SIGABRT: 6>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(line, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(p\u001b[38;5;241m.\u001b[39mreturncode, p\u001b[38;5;241m.\u001b[39margs)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLX_LM CLI TRAINING COMPLETE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['python', '-u', '-m', 'mlx_lm', 'lora', '--model', '/Users/f.nuno/Desktop/chatbot_2.0/LLM_training/models/mistral-7b-4bit', '--train', '--data', '/Users/f.nuno/Desktop/chatbot_2.0/LLM_training/data', '--batch-size', '4', '--iters', '100', '--learning-rate', '1e-05', '--num-layers', '4', '--max-seq-length', '2100', '--adapter-path', '/Users/f.nuno/Desktop/chatbot_2.0/LLM_training/checkpoints/adapters', '--val-batches', '25', '--steps-per-eval', '100', '--save-every', '100', '--seed', '0']' died with <Signals.SIGABRT: 6>."
     ]
    }
   ],
   "source": [
    "# Execute the training command\n",
    "print(\"\\\\n\" + \"=\"*70)\n",
    "print(\"STARTING MLX_LM CLI TRAINING\")\n",
    "print(\"=\"*70 + \"\\\\n\")\n",
    "\n",
    "try:\n",
    "    # Execute the command and show output in the terminal in real-time\n",
    "    with subprocess.Popen(\n",
    "        command, \n",
    "        stdout=subprocess.PIPE, \n",
    "        stderr=subprocess.STDOUT, \n",
    "        text=True, \n",
    "        bufsize=1, \n",
    "        universal_newlines=True\n",
    "    ) as p:\n",
    "        for line in p.stdout:\n",
    "            print(line, end='')\n",
    "\n",
    "    if p.returncode != 0:\n",
    "        raise subprocess.CalledProcessError(p.returncode, p.args)\n",
    "\n",
    "    print(\"\\\\n\" + \"=\"*70)\n",
    "    print(\"MLX_LM CLI TRAINING COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\\\n✓ All done!\")\n",
    "    print(f\"\\\\nMetrics and adapters saved in: {checkpoint_dir}/adapters/\")\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"\\\\n\\\\n❌ Error during MLX_LM CLI training: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"\\\\n\\\\n❌ An unexpected error occurred: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualize Training Metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUALIZING TRAINING METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "training_metrics_path = checkpoint_dir / \"training_metrics.csv\"\n",
    "\n",
    "if training_metrics_path.exists():\n",
    "    try:\n",
    "        df_metrics = pd.read_csv(training_metrics_path)\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        fig.suptitle('Training Metrics Overview', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Plot 1: Training Loss\n",
    "        if 'loss' in df_metrics.columns:\n",
    "            axes[0, 0].plot(df_metrics.index, df_metrics['loss'], 'b-', linewidth=2)\n",
    "            axes[0, 0].set_title('Training Loss')\n",
    "            axes[0, 0].set_xlabel('Step')\n",
    "            axes[0, 0].set_ylabel('Loss')\n",
    "            axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Validation Loss\n",
    "        if 'val_loss' in df_metrics.columns:\n",
    "            axes[0, 1].plot(df_metrics.index, df_metrics['val_loss'], 'r-', linewidth=2)\n",
    "            axes[0, 1].set_title('Validation Loss')\n",
    "            axes[0, 1].set_xlabel('Step')\n",
    "            axes[0, 1].set_ylabel('Loss')\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Learning Rate (if available)\n",
    "        if 'lr' in df_metrics.columns:\n",
    "            axes[1, 0].plot(df_metrics.index, df_metrics['lr'], 'g-', linewidth=2)\n",
    "            axes[1, 0].set_title('Learning Rate')\n",
    "            axes[1, 0].set_xlabel('Step')\n",
    "            axes[1, 0].set_ylabel('LR')\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1, 0].text(0.5, 0.5, 'Learning Rate\\ndata not available', \n",
    "                           ha='center', va='center', fontsize=12)\n",
    "            axes[1, 0].set_title('Learning Rate')\n",
    "        \n",
    "        # Plot 4: Training vs Validation Loss comparison\n",
    "        if 'loss' in df_metrics.columns and 'val_loss' in df_metrics.columns:\n",
    "            axes[1, 1].plot(df_metrics.index, df_metrics['loss'], 'b-', label='Training', linewidth=2)\n",
    "            axes[1, 1].plot(df_metrics.index, df_metrics['val_loss'], 'r-', label='Validation', linewidth=2)\n",
    "            axes[1, 1].set_title('Training vs Validation Loss')\n",
    "            axes[1, 1].set_xlabel('Step')\n",
    "            axes[1, 1].set_ylabel('Loss')\n",
    "            axes[1, 1].legend()\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(checkpoint_dir / 'training_metrics_plot.png', dpi=150, bbox_inches='tight')\n",
    "        print(\"✓ Training metrics plot saved to training_metrics_plot.png\")\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error visualizing metrics: {e}\")\n",
    "else:\n",
    "    print(\"⚠ No training metrics CSV found to visualize\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Detailed Quantitative Metrics Analysis\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED QUANTITATIVE METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "metrics_summary = {\n",
    "    'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'Model': 'Mistral-7B-4bit with LoRA',\n",
    "    'Adapter Path': adapter_path,\n",
    "}\n",
    "\n",
    "print(f\"\\nMetrics Summary:\")\n",
    "print(f\"  Timestamp: {metrics_summary['Timestamp']}\")\n",
    "print(f\"  Model: {metrics_summary['Model']}\")\n",
    "\n",
    "# Load and display training history\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"TRAINING HISTORY METRICS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "training_metrics_path = checkpoint_dir / \"training_metrics.csv\"\n",
    "if training_metrics_path.exists():\n",
    "    try:\n",
    "        df_metrics = pd.read_csv(training_metrics_path)\n",
    "        print(f\"\\n✓ Training metrics loaded ({len(df_metrics)} records)\")\n",
    "        print(f\"\\nMetrics columns: {list(df_metrics.columns)}\")\n",
    "        \n",
    "        # Display statistics for numerical columns\n",
    "        print(\"\\nTraining Metrics Statistics:\")\n",
    "        for col in df_metrics.select_dtypes(include=['float64', 'int64']).columns:\n",
    "            print(f\"\\n  {col}:\")\n",
    "            print(f\"    Min:    {df_metrics[col].min():.6f}\")\n",
    "            print(f\"    Max:    {df_metrics[col].max():.6f}\")\n",
    "            print(f\"    Mean:   {df_metrics[col].mean():.6f}\")\n",
    "            print(f\"    Std:    {df_metrics[col].std():.6f}\")\n",
    "            print(f\"    Final:  {df_metrics[col].iloc[-1]:.6f}\")\n",
    "        \n",
    "        # Display last few rows\n",
    "        print(\"\\n  Last 5 training steps:\")\n",
    "        print(df_metrics.tail().to_string())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading training metrics: {e}\")\n",
    "else:\n",
    "    print(\"⚠ Training metrics CSV not found\")\n",
    "\n",
    "# Validation metrics\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"VALIDATION SET METRICS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "try:\n",
    "    val_data_path = data_dir / \"valid.jsonl\"\n",
    "    if val_data_path.exists():\n",
    "        val_examples = []\n",
    "        with open(val_data_path, 'r') as f:\n",
    "            for line in f:\n",
    "                val_examples.append(json.loads(line))\n",
    "        \n",
    "        print(f\"\\n✓ Validation set: {len(val_examples)} samples\")\n",
    "        \n",
    "        # Text statistics\n",
    "        text_lengths = []\n",
    "        for ex in val_examples:\n",
    "            text = ex.get('text', '') or ex.get('instruction', '') or str(ex)\n",
    "            text_lengths.append(len(text.split()))\n",
    "        \n",
    "        text_lengths = np.array(text_lengths)\n",
    "        \n",
    "        print(f\"\\nText Length Statistics (tokens):\")\n",
    "        print(f\"  Mean:     {text_lengths.mean():.2f}\")\n",
    "        print(f\"  Median:   {np.median(text_lengths):.2f}\")\n",
    "        print(f\"  Std Dev:  {text_lengths.std():.2f}\")\n",
    "        print(f\"  Min:      {text_lengths.min()}\")\n",
    "        print(f\"  Max:      {text_lengths.max()}\")\n",
    "        print(f\"  Total:    {text_lengths.sum()}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"⚠ Error analyzing validation set: {e}\")\n",
    "\n",
    "# Model checkpoint info\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"MODEL CHECKPOINT INFORMATION\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "adapter_dir = Path(adapter_path)\n",
    "if adapter_dir.exists():\n",
    "    print(f\"\\n✓ Adapter directory exists: {adapter_dir}\")\n",
    "    \n",
    "    # List files in adapter directory\n",
    "    adapter_files = list(adapter_dir.glob('*'))\n",
    "    print(f\"\\nAdapter files ({len(adapter_files)} total):\")\n",
    "    for file in sorted(adapter_files)[:10]:  # Show first 10\n",
    "        size_mb = file.stat().st_size / (1024*1024)\n",
    "        print(f\"  {file.name:<40} {size_mb:>10.2f} MB\")\n",
    "    \n",
    "    if len(adapter_files) > 10:\n",
    "        print(f\"  ... and {len(adapter_files) - 10} more files\")\n",
    "else:\n",
    "    print(f\"\\n⚠ Adapter directory not found: {adapter_dir}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load and evaluate the trained model\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "import mlx.core as mx\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL EVALUATION AND TESTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load validation data\n",
    "print(\"\\n[1/5] Loading validation dataset...\")\n",
    "val_data_path = data_dir / \"valid.jsonl\"\n",
    "\n",
    "if not val_data_path.exists():\n",
    "    print(f\"❌ Validation data not found at {val_data_path}\")\n",
    "else:\n",
    "    val_examples = []\n",
    "    with open(val_data_path, 'r') as f:\n",
    "        for line in f:\n",
    "            val_examples.append(json.loads(line))\n",
    "    \n",
    "    print(f\"✓ Loaded {len(val_examples)} validation examples\")\n",
    "    \n",
    "    # Load training metrics if available\n",
    "    print(\"\\n[2/5] Loading training metrics...\")\n",
    "    metrics_path = checkpoint_dir / \"training_metrics.json\"\n",
    "    \n",
    "    if metrics_path.exists():\n",
    "        with open(metrics_path, 'r') as f:\n",
    "            metrics_data = json.load(f)\n",
    "        \n",
    "        print(\"✓ Training metrics found:\")\n",
    "        for key, value in metrics_data.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(\"⚠ No training metrics file found\")\n",
    "    \n",
    "    # Load adapter\n",
    "    print(\"\\n[3/5] Loading trained LoRA adapter...\")\n",
    "    try:\n",
    "        adapter_path_full = Path(adapter_path)\n",
    "        print(f\"✓ Adapter path: {adapter_path_full}\")\n",
    "        print(f\"  Adapter exists: {adapter_path_full.exists()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Warning loading adapter: {e}\")\n",
    "    \n",
    "    # Calculate perplexity on validation set\n",
    "    print(\"\\n[4/5] Computing validation metrics...\")\n",
    "    \n",
    "    try:\n",
    "        # Simple perplexity calculation based on text length\n",
    "        total_loss = 0\n",
    "        total_tokens = 0\n",
    "        \n",
    "        for example in val_examples[:min(100, len(val_examples))]:\n",
    "            # Get text from example (adjust field name as needed)\n",
    "            text = example.get('text', '') or example.get('instruction', '') or str(example)\n",
    "            tokens = len(text.split())\n",
    "            total_tokens += tokens\n",
    "        \n",
    "        avg_tokens = total_tokens / min(100, len(val_examples))\n",
    "        \n",
    "        print(f\"✓ Average tokens per sample: {avg_tokens:.2f}\")\n",
    "        print(f\"✓ Total validation tokens analyzed: {total_tokens}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error computing token statistics: {e}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n[5/5] Validation Dataset Summary:\")\n",
    "    print(f\"  Total samples: {len(val_examples)}\")\n",
    "    print(f\"  Sample size: {len(val_examples[:3])} (first 3)\")\n",
    "    \n",
    "    if val_examples:\n",
    "        print(f\"\\n  Sample example (first record):\")\n",
    "        first_example = val_examples[0]\n",
    "        for key, value in first_example.items():\n",
    "            if isinstance(value, str) and len(value) > 100:\n",
    "                print(f\"    {key}: {value[:100]}...\")\n",
    "            else:\n",
    "                print(f\"    {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
