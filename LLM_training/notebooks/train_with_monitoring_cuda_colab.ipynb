{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLX_LM LoRA Training with CUDA (Google Colab)\n",
    "\n",
    "Training a model with LoRA using GPU acceleration on Google Colab.\n",
    "\n",
    "**Note:** This notebook is optimized for Google Colab with NVIDIA GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Information (GPU/CUDA Detection)\n",
    "import platform\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SYSTEM INFORMATION & GPU DETECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Python info\n",
    "print(f\"Python Version:     {sys.version}\")\n",
    "print(f\"Python Executable:  {sys.executable}\")\n",
    "\n",
    "# Platform info\n",
    "print(f\"\\nPlatform:           {platform.platform()}\")\n",
    "print(f\"Machine Type:       {platform.machine()}\")\n",
    "\n",
    "# GPU/CUDA Detection\n",
    "print(f\"\\n\" + \"-\"*70)\n",
    "print(\"GPU/CUDA INFORMATION\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "try:\n",
    "    gpu_info = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)\n",
    "    if gpu_info.returncode == 0:\n",
    "        print(\"✓ NVIDIA GPU detected\")\n",
    "        print(\"\\nGPU Details:\")\n",
    "        for line in gpu_info.stdout.split('\\n')[:20]:\n",
    "            if line.strip():\n",
    "                print(line)\n",
    "    else:\n",
    "        print(\"❌ No NVIDIA GPU detected\")\nexcept Exception as e:\n",
    "    print(f\"⚠ Could not detect GPU: {e}\")\n",
    "\n",
    "# Check PyTorch/TensorFlow CUDA availability\n",
    "print(f\"\\n\" + \"-\"*70)\n",
    "print(\"DEEP LEARNING FRAMEWORK CUDA SUPPORT\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\n✓ PyTorch {torch.__version__} installed\")\n",
    "    print(f\"  CUDA available:    {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  CUDA version:      {torch.version.cuda}\")\n",
    "        print(f\"  GPU count:         {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"  GPU {i}:            {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  Current GPU:       {torch.cuda.current_device()}\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed\")\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"\\n✓ TensorFlow {tf.__version__} installed\")\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(f\"  GPUs detected:     {len(gpus)}\")\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            print(f\"    - {gpu}\")\n",
    "except ImportError:\n",
    "    print(\"TensorFlow not installed\")\n",
    "\n",
    "print(f\"\\nCurrent Directory:  {os.getcwd()}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Colab training\n",
    "print(\"Installing required packages...\")\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    'torch',\n",
    "    'transformers',\n",
    "    'datasets',\n",
    "    'peft',  # For LoRA\n",
    "    'bitsandbytes',  # For quantization\n",
    "    'psutil',\n",
    "    'pandas',\n",
    "    'scikit-learn',\n",
    "    'matplotlib'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"\\nInstalling {package}...\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
    "        print(f\"✓ {package} installed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error installing {package}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Package installation complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (for accessing training data)\n",
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MOUNTING GOOGLE DRIVE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"\\n✓ Google Drive mounted successfully\")\n",
    "    \n",
    "    # List contents\n",
    "    drive_path = Path('/content/drive/MyDrive')\n",
    "    print(f\"\\nDrive contents:\")\n",
    "    for item in list(drive_path.iterdir())[:10]:\n",
    "        print(f\"  - {item.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Could not mount Google Drive: {e}\")\n",
    "    print(\"You can upload data manually or use a different method.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and configuration\n",
    "from pathlib import Path\n",
    "\n",
    "# For Colab: use /content directory\n",
    "# You can modify these paths based on where your data is stored\n",
    "\n",
    "project_root = Path(\"/content/LLM_training\")\n",
    "project_root.mkdir(exist_ok=True)\n",
    "\n",
    "data_dir = project_root / \"data\"\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "checkpoint_dir = project_root / \"checkpoints\"\n",
    "checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "model_cache_dir = project_root / \"model_cache\"\n",
    "model_cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Model from Hugging Face\n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"  # or \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "adapter_path = str(checkpoint_dir / \"adapters\")\n",
    "Path(adapter_path).mkdir(exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PATHS CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Project Root:       {project_root}\")\n",
    "print(f\"Data Directory:     {data_dir}\")\n",
    "print(f\"Checkpoint Dir:     {checkpoint_dir}\")\n",
    "print(f\"Model Cache:        {model_cache_dir}\")\n",
    "print(f\"Adapter Path:       {adapter_path}\")\n",
    "print(f\"Model Name:         {model_name}\")\n",
    "print(f\"\\nData directory exists: {data_dir.exists()}\")\n",
    "print(f\"Checkpoint directory exists: {checkpoint_dir.exists()}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload or prepare training data\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATA PREPARATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Option 1: Upload from Google Drive\n",
    "print(\"\\n[Option 1] Check for data in Google Drive...\")\n",
    "drive_data = Path(\"/content/drive/MyDrive/LLM_training/data\")\n",
    "if drive_data.exists():\n",
    "    print(f\"✓ Found data in Drive: {drive_data}\")\n",
    "    # Copy to local storage\n",
    "    import shutil\n",
    "    for file in drive_data.glob(\"*.jsonl\"):\n",
    "        print(f\"  Copying {file.name}...\")\n",
    "        shutil.copy(file, data_dir / file.name)\nexcept:\n",
    "    print(f\"✗ No data found in Drive\")\n",
    "\n",
    "# Option 2: Check local /content/data\n",
    "print(\"\\n[Option 2] Check for uploaded data...\")\nlocal_data = Path(\"/content/data\")\nif local_data.exists():\n",
    "    print(f\"✓ Found local data: {local_data}\")\n",
    "    import shutil\n",
    "    for file in local_data.glob(\"*.jsonl\"):\n",
    "        print(f\"  Copying {file.name}...\")\n",
    "        shutil.copy(file, data_dir / file.name)\n",
    "else:\n",
    "    print(f\"✗ No local data found\")\n",
    "\n",
    "# Show available data\n",
    "print(f\"\\nAvailable training data in {data_dir}:\")\ndata_files = list(data_dir.glob(\"*.jsonl\"))\nif data_files:\n",
    "    for file in data_files:\n",
    "        size_mb = file.stat().st_size / (1024*1024)\n",
    "        with open(file, 'r') as f:\n",
    "            lines = sum(1 for _ in f)\n",
    "        print(f\"  ✓ {file.name:<30} {size_mb:>8.2f} MB ({lines} samples)\")\n",
    "else:\n",
    "    print(\"  No JSONL files found. Upload data to continue.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters for CUDA/GPU\n",
    "import torch\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING PARAMETERS (GPU-Optimized)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# GPU Memory optimization\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"Available GPU Memory: {gpu_memory:.2f} GB\")\n",
    "    \n",
    "    # Auto-adjust batch size based on GPU memory\n",
    "    if gpu_memory >= 16:\n",
    "        batch_size = 16\n",
    "    elif gpu_memory >= 8:\n",
    "        batch_size = 8\n",
    "    else:\n",
    "        batch_size = 4\nelse:\n",
    "    batch_size = 2\n",
    "    print(\"No GPU detected, using CPU (slow!)\")\n",
    "\n",
    "# Training parameters\n",
    "iters = 100\n",
    "learning_rate = 2e-4\n",
    "lora_rank = 8\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.05\n",
    "max_seq_length = 512  # Adjust based on your needs and GPU memory\n",
    "val_batches = 25\n",
    "val_interval = 10\n",
    "save_every = 10\n",
    "seed = 42\n",
    "num_train_epochs = 3\n",
    "warmup_steps = 500\n",
    "weight_decay = 0.01\n",
    "use_gradient_checkpointing = True\n",
    "use_mixed_precision = True  # fp16 training for memory efficiency\n",
    "\n",
    "print(f\"\\nBatch Size:              {batch_size}\")\n",
    "print(f\"Iterations:              {iters}\")\n",
    "print(f\"Epochs:                  {num_train_epochs}\")\n",
    "print(f\"Learning Rate:           {learning_rate}\")\n",
    "print(f\"LoRA Rank:               {lora_rank}\")\n",
    "print(f\"LoRA Alpha:              {lora_alpha}\")\n",
    "print(f\"LoRA Dropout:            {lora_dropout}\")\n",
    "print(f\"Max Seq Length:          {max_seq_length}\")\n",
    "print(f\"Validation Batches:      {val_batches}\")\n",
    "print(f\"Validation Interval:     {val_interval}\")\n",
    "print(f\"Save Every:              {save_every}\")\n",
    "print(f\"Gradient Checkpointing:  {use_gradient_checkpointing}\")\n",
    "print(f\"Mixed Precision (fp16):  {use_mixed_precision}\")\n",
    "print(f\"Warmup Steps:            {warmup_steps}\")\n",
    "print(f\"Weight Decay:            {weight_decay}\")\n",
    "print(f\"Seed:                    {seed}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and prepare for training with LoRA\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import torch\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADING MODEL AND PREPARING LoRA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\n[1/3] Using device: {device}\")\n",
    "\n",
    "# Quantization config for memory efficiency\n",
    "print(f\"\\n[2/3] Loading model: {model_name}\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(f\"✓ Tokenizer loaded\")\n",
    "    \n",
    "    # Load model with quantization\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        cache_dir=str(model_cache_dir),\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    print(f\"✓ Model loaded and quantized (4-bit)\")\n",
    "    \n",
    "    # Configure LoRA\n",
    "    print(f\"\\n[3/3] Configuring LoRA...\")\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        r=lora_rank,\n",
    "        lora_alpha=lora_alpha,\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        inference_mode=False,\n",
    "    )\n",
    "    \n",
    "    model = get_peft_model(model, peft_config)\n",
    "    print(f\"✓ LoRA configured\")\n",
    "    \n",
    "    # Print trainable parameters\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\nModel Parameters:\")\n",
    "    print(f\"  Trainable: {trainable_params:,}\")\n",
    "    print(f\"  Total:     {total_params:,}\")\n",
    "    print(f\"  % Trainable: {100 * trainable_params / total_params:.2f}%\")\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"❌ Error loading model: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data and create DataLoader\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADING TRAINING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Load JSONL files into dataset\n",
    "    train_file = data_dir / \"train.jsonl\"\n",
    "    val_file = data_dir / \"valid.jsonl\"\n",
    "    \n",
    "    print(f\"\\nLoading training data from {train_file}...\")\n",
    "    if train_file.exists():\n",
    "        train_dataset = load_dataset('json', data_files=str(train_file), split='train')\n",
    "        print(f\"✓ Training dataset loaded: {len(train_dataset)} samples\")\n",
    "    else:\n",
    "        print(f\"❌ Training file not found: {train_file}\")\n",
    "        train_dataset = None\n",
    "    \n",
    "    print(f\"\\nLoading validation data from {val_file}...\")\n",
    "    if val_file.exists():\n",
    "        val_dataset = load_dataset('json', data_files=str(val_file), split='train')\n",
    "        print(f\"✓ Validation dataset loaded: {len(val_dataset)} samples\")\n",
    "    else:\n",
    "        print(f\"⚠ Validation file not found: {val_file}\")\n",
    "        val_dataset = None\n",
    "    \n",
    "    # Show sample\n",
    "    if train_dataset:\n",
    "        print(f\"\\nSample training example:\")\n",
    "        sample = train_dataset[0]\n",
    "        for key, value in sample.items():\n",
    "            if isinstance(value, str) and len(value) > 100:\n",
    "                print(f\"  {key}: {value[:100]}...\")\n",
    "            else:\n",
    "                print(f\"  {key}: {value}\")\n",
    "\nexcept Exception as e:\n",
    "    print(f\"❌ Error loading data: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training with HuggingFace Trainer\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "import json\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING SETUP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_function(examples):\n",
    "    # Get text field (adjust based on your data structure)\n",
    "    texts = examples.get('text') or examples.get('instruction') or examples.get('content')\n",
    "    \n",
    "    result = tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_seq_length,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].clone()\n",
    "    return result\n",
    "\n",
    "print(\"\\nTokenizing datasets...\")\nif train_dataset:\n",
    "    train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=train_dataset.column_names)\n",
    "    print(f\"✓ Training data tokenized\")\n",
    "\nif val_dataset:\n",
    "    val_dataset = val_dataset.map(tokenize_function, batched=True, remove_columns=val_dataset.column_names)\n",
    "    print(f\"✓ Validation data tokenized\")\n",
    "\n# Training arguments\ntraining_args = TrainingArguments(\n",
    "    output_dir=str(checkpoint_dir / \"training_output\"),\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=warmup_steps,\n",
    "    weight_decay=weight_decay,\n",
    "    logging_dir=str(checkpoint_dir / \"logs\"),\n",
    "    logging_steps=10,\n",
    "    save_steps=save_every,\n",
    "    eval_steps=val_interval,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    learning_rate=learning_rate,\n",
    "    seed=seed,\n",
    "    fp16=use_mixed_precision,\n",
    "    gradient_checkpointing=use_gradient_checkpointing,\n",
    "    gradient_accumulation_steps=1,\n",
    ")\n",
    "\nprint(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Output dir:          {training_args.output_dir}\")\n",
    "print(f\"Epochs:              {training_args.num_train_epochs}\")\n",
    "print(f\"Batch size:          {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Learning rate:       {training_args.learning_rate}\")\n",
    "print(f\"FP16:                {training_args.fp16}\")\n",
    "print(f\"Grad checkpointing:  {training_args.gradient_checkpointing}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute training\nfrom transformers import Trainer\n\nprint(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\ntry:\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset if train_dataset else None,\n",
    "        eval_dataset=val_dataset if val_dataset else None,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    \n",
    "    print(\"Starting training loop...\\n\")\n",
    "    train_result = trainer.train()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nTraining Results:\")\n",
    "    print(f\"  Final Loss:    {train_result.training_loss:.6f}\")\n",
    "    \n",
    "    # Save adapter\n",
    "    print(f\"\\nSaving LoRA adapter...\")\n",
    "    model.save_pretrained(adapter_path)\n",
    "    print(f\"✓ Adapter saved to: {adapter_path}\")\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"\\n❌ Training error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation and Testing\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL EVALUATION AND TESTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load validation data\n",
    "print(\"\\n[1/4] Loading validation dataset...\")\n",
    "val_data_path = data_dir / \"valid.jsonl\"\n",
    "\n",
    "if not val_data_path.exists():\n",
    "    print(f\"❌ Validation data not found at {val_data_path}\")\n",
    "else:\n",
    "    val_examples = []\n",
    "    with open(val_data_path, 'r') as f:\n",
    "        for line in f:\n",
    "            val_examples.append(json.loads(line))\n",
    "    \n",
    "    print(f\"✓ Loaded {len(val_examples)} validation examples\")\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    print(\"\\n[2/4] Computing validation metrics...\")\n",
    "    \n",
    "    total_tokens = 0\n",
    "    text_lengths = []\n",
    "    \n",
    "    for example in val_examples:\n",
    "        text = example.get('text', '') or example.get('instruction', '') or str(example)\n",
    "        tokens = len(tokenizer.encode(text))\n",
    "        total_tokens += tokens\n",
    "        text_lengths.append(tokens)\n",
    "    \n",
    "    text_lengths = np.array(text_lengths)\n",
    "    \n",
    "    print(f\"\\nValidation Metrics:\")\n",
    "    print(f\"  Total samples:       {len(val_examples)}\")\n",
    "    print(f\"  Total tokens:        {total_tokens:,}\")\n",
    "    print(f\"  Mean tokens/sample:  {text_lengths.mean():.2f}\")\n",
    "    print(f\"  Median tokens:       {np.median(text_lengths):.2f}\")\n",
    "    print(f\"  Std Dev:             {text_lengths.std():.2f}\")\n",
    "    print(f\"  Min tokens:          {text_lengths.min()}\")\n",
    "    print(f\"  Max tokens:          {text_lengths.max()}\")\n",
    "    \n",
    "    # Load training metrics if available\n",
    "    print(\"\\n[3/4] Loading training history...\")\n",
    "    training_log_file = checkpoint_dir / \"training_output\" / \"trainer_state.json\"\n",
    "    \n",
    "    if training_log_file.exists():\n",
    "        with open(training_log_file, 'r') as f:\n",
    "            trainer_state = json.load(f)\n",
    "        \n",
    "        print(f\"✓ Training history loaded\")\n",
    "        if 'log_history' in trainer_state:\n",
    "            print(f\"\\nTraining History Summary:\")\n",
    "            logs = trainer_state['log_history']\n",
    "            \n",
    "            train_losses = [log.get('loss', None) for log in logs if 'loss' in log]\n",
    "            eval_losses = [log.get('eval_loss', None) for log in logs if 'eval_loss' in log]\n",
    "            \n",
    "            if train_losses:\n",
    "                print(f\"  Training Loss - Min: {min(train_losses):.6f}, Max: {max(train_losses):.6f}, Final: {train_losses[-1]:.6f}\")\n",
    "            if eval_losses:\n",
    "                print(f\"  Validation Loss - Min: {min(eval_losses):.6f}, Max: {max(eval_losses):.6f}, Final: {eval_losses[-1]:.6f}\")\n",
    "    else:\n",
    "        print(f\"⚠ Training history not found\")\n",
    "    \n",
    "    # Adapter info\n",
    "    print(\"\\n[4/4] Adapter Information...\")\n",
    "    adapter_dir = Path(adapter_path)\n",
    "    if adapter_dir.exists():\n",
    "        adapter_files = list(adapter_dir.glob('*'))\n",
    "        print(f\"✓ Adapter saved with {len(adapter_files)} files\")\n",
    "        total_size_mb = sum(f.stat().st_size for f in adapter_files if f.is_file()) / (1024*1024)\n",
    "        print(f\"  Total size: {total_size_mb:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"⚠ Adapter directory not found\")\n",
    "\nprint(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Quantitative Metrics Analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED QUANTITATIVE METRICS ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "metrics_summary = {\n",
    "    'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'Model': model_name,\n",
    "    'Training Framework': 'HuggingFace Transformers + PEFT (LoRA)',\n",
    "    'Device': 'CUDA GPU',\n",
    "    'Adapter Path': adapter_path,\n",
    "}\n",
    "\n",
    "print(f\"\\nMetrics Summary:\")\n",
    "for key, value in metrics_summary.items():\n",
    "    print(f\"  {key:<25}: {value}\")\n",
    "\n",
    "# Load training logs\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"TRAINING HISTORY ANALYSIS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "training_log_file = checkpoint_dir / \"training_output\" / \"trainer_state.json\"\n",
    "\n",
    "if training_log_file.exists():\n",
    "    try:\n",
    "        with open(training_log_file, 'r') as f:\n",
    "            trainer_state = json.load(f)\n",
    "        \n",
    "        logs = trainer_state.get('log_history', [])\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df_logs = pd.DataFrame(logs)\n",
    "        print(f\"\\n✓ Loaded {len(df_logs)} training records\")\n",
    "        print(f\"\\nColumns: {list(df_logs.columns)}\")\n",
    "        \n",
    "        # Statistics\n",
    "        numeric_cols = df_logs.select_dtypes(include=['float64', 'int64']).columns\n",
    "        print(f\"\\nMetrics Statistics:\")\n",
    "        for col in numeric_cols:\n",
    "            if df_logs[col].notna().any():\n",
    "                print(f\"\\n  {col}:\")\n",
    "                print(f\"    Min:    {df_logs[col].min():.6f}\")\n",
    "                print(f\"    Max:    {df_logs[col].max():.6f}\")\n",
    "                print(f\"    Mean:   {df_logs[col].mean():.6f}\")\n",
    "                print(f\"    Std:    {df_logs[col].std():.6f}\")\n",
    "                print(f\"    Final:  {df_logs[col].dropna().iloc[-1]:.6f}\")\n",
    "        \n",
    "        # Display last few steps\n",
    "        print(f\"\\n  Last 5 training steps:\")\n",
    "        print(df_logs[['step', 'loss', 'eval_loss']].tail() if 'step' in df_logs.columns else df_logs.tail())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading training logs: {e}\")\nelse:\n",
    "    print(f\"⚠ Training logs not found at {training_log_file}\")\n",
    "\nprint(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Training Metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUALIZING TRAINING METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "training_log_file = checkpoint_dir / \"training_output\" / \"trainer_state.json\"\n",
    "\n",
    "if training_log_file.exists():\n",
    "    try:\n",
    "        with open(training_log_file, 'r') as f:\n",
    "            trainer_state = json.load(f)\n",
    "        \n",
    "        logs = trainer_state.get('log_history', [])\n",
    "        df_logs = pd.DataFrame(logs)\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        fig.suptitle('Training Metrics Overview (CUDA/GPU)', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Plot 1: Training Loss\n",
    "        if 'loss' in df_logs.columns:\n",
    "            loss_data = df_logs[df_logs['loss'].notna()]\n",
    "            axes[0, 0].plot(loss_data['step'], loss_data['loss'], 'b-', linewidth=2, marker='o')\n",
    "            axes[0, 0].set_title('Training Loss')\n",
    "            axes[0, 0].set_xlabel('Step')\n",
    "            axes[0, 0].set_ylabel('Loss')\n",
    "            axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Validation Loss\n",
    "        if 'eval_loss' in df_logs.columns:\n",
    "            eval_data = df_logs[df_logs['eval_loss'].notna()]\n",
    "            axes[0, 1].plot(eval_data['step'], eval_data['eval_loss'], 'r-', linewidth=2, marker='s')\n",
    "            axes[0, 1].set_title('Validation Loss')\n",
    "            axes[0, 1].set_xlabel('Step')\n",
    "            axes[0, 1].set_ylabel('Loss')\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Learning Rate (if available)\n",
    "        if 'learning_rate' in df_logs.columns:\n",
    "            lr_data = df_logs[df_logs['learning_rate'].notna()]\n",
    "            axes[1, 0].plot(lr_data['step'], lr_data['learning_rate'], 'g-', linewidth=2)\n",
    "            axes[1, 0].set_title('Learning Rate')\n",
    "            axes[1, 0].set_xlabel('Step')\n",
    "            axes[1, 0].set_ylabel('LR')\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1, 0].text(0.5, 0.5, 'Learning Rate\\ndata not available', \n",
    "                           ha='center', va='center', fontsize=12)\n",
    "            axes[1, 0].set_title('Learning Rate')\n",
    "        \n",
    "        # Plot 4: Training vs Validation Loss comparison\n",
    "        if 'loss' in df_logs.columns and 'eval_loss' in df_logs.columns:\n",
    "            train_data = df_logs[df_logs['loss'].notna()]\n",
    "            eval_data = df_logs[df_logs['eval_loss'].notna()]\n",
    "            axes[1, 1].plot(train_data['step'], train_data['loss'], 'b-', label='Training', linewidth=2)\n",
    "            axes[1, 1].plot(eval_data['step'], eval_data['eval_loss'], 'r-', label='Validation', linewidth=2)\n",
    "            axes[1, 1].set_title('Training vs Validation Loss')\n",
    "            axes[1, 1].set_xlabel('Step')\n",
    "            axes[1, 1].set_ylabel('Loss')\n",
    "            axes[1, 1].legend()\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        plot_path = checkpoint_dir / 'training_metrics_plot_cuda.png'\n",
    "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"✓ Training metrics plot saved to {plot_path}\")\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error visualizing metrics: {e}\")\nelse:\n",
    "    print(\"⚠ No training metrics to visualize\")\n",
    "\nprint(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained adapter and cleanup\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"POST-TRAINING TASKS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save to Google Drive\n",
    "print(\"\\n[1/2] Saving results to Google Drive...\")\ntry:\n",
    "    drive_output = Path(\"/content/drive/MyDrive/LLM_training_output\")\n",
    "    drive_output.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Copy adapter\n",
    "    adapter_drive = drive_output / \"adapters\"\n",
    "    if adapter_drive.exists():\n",
    "        shutil.rmtree(adapter_drive)\n",
    "    shutil.copytree(adapter_path, adapter_drive)\n",
    "    print(f\"✓ Adapter saved to Google Drive: {adapter_drive}\")\n",
    "    \n",
    "    # Copy metrics and plots\n",
    "    for file in checkpoint_dir.glob('*.png'):\n",
    "        shutil.copy(file, drive_output / file.name)\n",
    "        print(f\"✓ Saved {file.name} to Drive\")\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"⚠ Could not save to Drive: {e}\")\n",
    "\nprint(\"\\n[2/2] Training Summary\")\nprint(f\"\\n✓ Training completed successfully!\")\nprint(f\"  Model: {model_name}\")\nprint(f\"  LoRA Adapter saved at: {adapter_path}\")\nprint(f\"  Checkpoint directory: {checkpoint_dir}\")\n",
    "print(f\"\\nTo use the trained model:\")\n",
    "print(f\"  from peft import PeftModel\")\n",
    "print(f\"  model = PeftModel.from_pretrained(model, '{adapter_path}')\")\n",
    "\nprint(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL DONE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
