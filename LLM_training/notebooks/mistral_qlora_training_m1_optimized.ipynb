{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QLoRA Training - Otimizado para MacBook Pro M1 16GB\n",
    "\n",
    "Este notebook est√° otimizado especificamente para:\n",
    "- **Hardware:** MacBook Pro M1 16GB RAM\n",
    "- **Modelo:** Mistral-7B quantizado (INT4)\n",
    "- **M√©todo:** QLoRA (Low-Rank Adaptation)\n",
    "- **Dataset:** Farense (943 exemplos, 90/10 split)\n",
    "\n",
    "**Tempo de Treino Estimado:** 2-3 horas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se√ß√£o 1: Configura√ß√£o e Verifica√ß√£o do Sistema\n",
    "\n",
    "Verificar hardware, GPU e depend√™ncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Imports b√°sicos\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"‚úì Imports b√°sicos OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Verificar MLX e GPU Metal\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "print(\"‚úì MLX imports OK\")\n",
    "\n",
    "# Verificar dispositivo\n",
    "try:\n",
    "    mx.set_default_device(mx.gpu)\n",
    "    device = mx.default_device()\n",
    "    print(f\"‚úì GPU Metal ativado: {device}\")\nexcept Exception as e:\n",
    "    print(f\"‚ö† Warning: {e}\")\n",
    "    print(f\"‚úì CPU mode: {mx.default_device()}\")\n",
    "\n",
    "print(f\"‚úì MLX version: {mx.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Verificar mem√≥ria dispon√≠vel\n",
    "import psutil\n",
    "\n",
    "memory = psutil.virtual_memory()\n",
    "print(f\"\\nüìä MEM√ìRIA DO SISTEMA:\")\n",
    "print(f\"  Total: {memory.total / 1e9:.1f} GB\")\n",
    "print(f\"  Dispon√≠vel: {memory.available / 1e9:.1f} GB\")\n",
    "print(f\"  Usada: {memory.used / 1e9:.1f} GB ({memory.percent}%)\")\n",
    "print(f\"\\n‚úì Sistema M1 com {memory.total / 1e9:.0f}GB RAM detectado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Se√ß√£o 2: Configura√ß√£o de Treino (IMPORTANTE)\n",
    "\n",
    "### ‚öôÔ∏è CONFIGURA√á√ïES OTIMIZADAS PARA M1 16GB\n",
    "\n",
    "Estas s√£o as configura√ß√µes recomendadas para seu MacBook Pro M1 16GB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURA√á√ïES PARA MACBOOK PRO M1 16GB\n",
    "# ============================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configura√ß√µes de treino otimizadas para M1 16GB\"\"\"\n",
    "    \n",
    "    # ===== PATHS =====\n",
    "    project_root = Path(\"/Users/f.nuno/Desktop/chatbot_2.0/LLM_training\")\n",
    "    data_dir = project_root / \"data\"\n",
    "    model_dir = project_root / \"models\" / \"mistral-7b-4bit\"\n",
    "    checkpoint_dir = project_root / \"checkpoints_qlora\"\n",
    "    output_dir = project_root / \"output\" / \"mistral-7b-farense-qlora\"\n",
    "    \n",
    "    # ===== DATA =====\n",
    "    train_file = data_dir / \"train.jsonl\"\n",
    "    valid_file = data_dir / \"valid.jsonl\"\n",
    "    \n",
    "    # ===== TRAINING HYPERPARAMETERS (M1 16GB OPTIMIZED) =====\n",
    "    # Batch size: 4 √© seguro para M1 16GB com QLoRA\n",
    "    # Com gradient_accumulation=2, effective_batch_size = 8\n",
    "    batch_size = 4                          # ‚Üê IMPORTANTE: Batch size para M1 16GB\n",
    "    gradient_accumulation_steps = 2         # Accumula gradientes (effective batch = 8)\n",
    "    learning_rate = 2e-4                    # Taxa de aprendizagem padr√£o para LoRA\n",
    "    num_epochs = 3                          # 3 √©pocas recomendado\n",
    "    warmup_steps = 100                      # Aquecimento do LR\n",
    "    max_seq_length = 512                    # Comprimento m√°ximo de sequ√™ncia\n",
    "    \n",
    "    # ===== VALIDATION & CHECKPOINTING =====\n",
    "    eval_steps = 200                        # Valida√ß√£o a cada 200 passos\n",
    "    save_steps = 200                        # Salvar checkpoint a cada 200 passos\n",
    "    log_steps = 10                          # Log a cada 10 passos\n",
    "    \n",
    "    # ===== LoRA CONFIGURATION =====\n",
    "    lora_rank = 8                           # Rank de decomposi√ß√£o LoRA\n",
    "    lora_scale = 16                         # Scaling factor\n",
    "    lora_dropout = 0.0                      # Sem dropout para dataset pequeno\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ]                                       # M√≥dulos onde aplicar LoRA\n",
    "    \n",
    "    # ===== QUANTIZATION =====\n",
    "    quantization_bits = 4                   # INT4 quantization\n",
    "    group_size = 64                         # Tamanho de grupo de quantiza√ß√£o\n",
    "    \n",
    "    # ===== SYSTEM =====\n",
    "    seed = 42                               # Reprodutibilidade\n",
    "    device = \"gpu\"                          # Metal GPU\n",
    "\n",
    "# Criar diret√≥rios se n√£o existirem\n",
    "Config.checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "Config.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚öôÔ∏è  CONFIGURA√á√ïES DE TREINO - MACBOOK PRO M1 16GB\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "üéØ TRAINING PARAMETERS:\n",
    "  ‚Ä¢ Batch Size:                 {Config.batch_size}\n",
    "  ‚Ä¢ Gradient Accumulation:      {Config.gradient_accumulation_steps}\n",
    "  ‚Ä¢ Effective Batch Size:       {Config.batch_size * Config.gradient_accumulation_steps}\n",
    "  ‚Ä¢ Learning Rate:              {Config.learning_rate}\n",
    "  ‚Ä¢ Number of Epochs:           {Config.num_epochs}\n",
    "  ‚Ä¢ Max Sequence Length:        {Config.max_seq_length}\n",
    "  ‚Ä¢ Warmup Steps:               {Config.warmup_steps}\n",
    "\n",
    "üìä CHECKPOINTING & VALIDATION:\n",
    "  ‚Ä¢ Save Checkpoint Every:      {Config.save_steps} steps\n",
    "  ‚Ä¢ Evaluate Every:             {Config.eval_steps} steps\n",
    "  ‚Ä¢ Log Every:                  {Config.log_steps} steps\n",
    "\n",
    "üéõÔ∏è  LoRA CONFIGURATION:\n",
    "  ‚Ä¢ LoRA Rank:                  {Config.lora_rank}\n",
    "  ‚Ä¢ LoRA Scale:                 {Config.lora_scale}\n",
    "  ‚Ä¢ LoRA Dropout:               {Config.lora_dropout}\n",
    "  ‚Ä¢ Target Modules:             {len(Config.target_modules)} (q,v,k,o,gate,up,down)\n",
    "\n",
    "üíæ QUANTIZATION:\n",
    "  ‚Ä¢ Bits:                       {Config.quantization_bits}-bit INT\n",
    "  ‚Ä¢ Group Size:                 {Config.group_size}\n",
    "\n",
    "üìÇ PATHS:\n",
    "  ‚Ä¢ Train Data:                 {Config.train_file.name}\n",
    "  ‚Ä¢ Valid Data:                 {Config.valid_file.name}\n",
    "  ‚Ä¢ Model:                      {Config.model_dir.name}\n",
    "  ‚Ä¢ Checkpoints:                {Config.checkpoint_dir.name}\n",
    "  ‚Ä¢ Output:                     {Config.output_dir.name}\n",
    "\"\"\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Summary\n",
    "print(\"\\n‚úÖ Configura√ß√µes carregadas e validadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Se√ß√£o 3: Carregamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Carregar dados de treino\n",
    "print(f\"[INFO] Carregando dados de treino de {Config.train_file}...\")\n",
    "\n",
    "train_data = []\n",
    "with open(Config.train_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            record = json.loads(line)\n",
    "            train_data.append(record)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"[WARN] Linha inv√°lida ignorada: {e}\")\n",
    "\n",
    "print(f\"‚úì {len(train_data)} exemplos de treino carregados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Carregar dados de valida√ß√£o\n",
    "print(f\"[INFO] Carregando dados de valida√ß√£o de {Config.valid_file}...\")\n",
    "\n",
    "valid_data = []\n",
    "with open(Config.valid_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            record = json.loads(line)\n",
    "            valid_data.append(record)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"[WARN] Linha inv√°lida ignorada: {e}\")\n",
    "\n",
    "print(f\"‚úì {len(valid_data)} exemplos de valida√ß√£o carregados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Mostrar amostra de dados\n",
    "print(\"\\nüìå AMOSTRA DE DADOS:\")\n",
    "print(\"=\"*70)\n",
    "sample = train_data[0]\n",
    "print(f\"\\nPergunta: {sample['prompt']}\")\n",
    "print(f\"\\nResposta: {sample['completion'][:100]}...\")\n",
    "print(f\"\\nTipo: {sample['metadata'].get('tipo', 'unknown')}\")\n",
    "print(f\"√âpoca: {sample['metadata'].get('epoca', 'unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Se√ß√£o 4: Carregar Modelo Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Carregar modelo e tokenizer\n",
    "print(f\"\\n[INFO] Carregando modelo de {Config.model_dir}...\")\n",
    "print(\"[INFO] Isto pode levar 1-2 minutos na primeira vez...\")\n",
    "\n",
    "start_load = time.time()\n",
    "\n",
    "try:\n",
    "    model, tokenizer = load(str(Config.model_dir))\n",
    "    elapsed = time.time() - start_load\n",
    "    print(f\"‚úì Modelo carregado em {elapsed:.1f}s\")\nexcept Exception as e:\n",
    "    print(f\"‚ùå Erro ao carregar modelo: {e}\")\n",
    "    print(f\"Tentando carregar de Hugging Face...\")\n",
    "    model, tokenizer = load(\"mistralai/Mistral-7B-v0.1\")\n",
    "    print(f\"‚úì Modelo carregado de HF em {time.time() - start_load:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Verificar modelo\n",
    "print(f\"\"\"\n",
    "‚úì Modelo carregado com sucesso:\n",
    "  ‚Ä¢ Tipo: {type(model).__name__}\n",
    "  ‚Ä¢ Par√¢metros: {sum(p.size for p in model.parameters()):,}\n",
    "  ‚Ä¢ Tokenizer: {type(tokenizer).__name__}\n",
    "  ‚Ä¢ Vocab Size: {len(tokenizer)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Se√ß√£o 5: Prepara√ß√£o de Dados (Tokeniza√ß√£o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Fun√ß√£o de tokeniza√ß√£o\n",
    "def tokenize_example(example, tokenizer, max_length):\n",
    "    \"\"\"\n",
    "    Tokeniza um exemplo combinando prompt e completion.\n",
    "    Formato: \"### Pergunta:\\n{prompt}\\n\\n### Resposta:\\n{completion}\"\n",
    "    \"\"\"\n",
    "    prompt = example.get('prompt', '')\n",
    "    completion = example.get('completion', '')\n",
    "    \n",
    "    # Format instruction\n",
    "    text = f\"### Pergunta:\\n{prompt}\\n\\n### Resposta:\\n{completion}\"\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = tokenizer.encode(text)\n",
    "    \n",
    "    # Truncate if needed\n",
    "    if len(tokens) > max_length:\n",
    "        tokens = tokens[:max_length]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# 5.2 Tokenizar dados\n",
    "print(\"[INFO] Tokenizando dados de treino...\")\n",
    "train_tokens = []\n",
    "skipped = 0\n",
    "\n",
    "for i, example in enumerate(train_data):\n",
    "    try:\n",
    "        tokens = tokenize_example(example, tokenizer, Config.max_seq_length)\n",
    "        if len(tokens) >= 8:  # Filtrar exemplos muito curtos\n",
    "            train_tokens.append(tokens)\n",
    "        else:\n",
    "            skipped += 1\n",
    "    except Exception as e:\n",
    "        skipped += 1\n",
    "        if i < 3:\n",
    "            print(f\"[WARN] Erro na tokeniza√ß√£o do exemplo {i}: {e}\")\n",
    "\n",
    "print(f\"‚úì {len(train_tokens)} exemplos de treino tokenizados (ignorados: {skipped})\")\n",
    "\n",
    "# 5.3 Tokenizar dados de valida√ß√£o\n",
    "print(\"[INFO] Tokenizando dados de valida√ß√£o...\")\n",
    "valid_tokens = []\n",
    "skipped = 0\n",
    "\n",
    "for i, example in enumerate(valid_data):\n",
    "    try:\n",
    "        tokens = tokenize_example(example, tokenizer, Config.max_seq_length)\n",
    "        if len(tokens) >= 8:\n",
    "            valid_tokens.append(tokens)\n",
    "        else:\n",
    "            skipped += 1\n",
    "    except Exception as e:\n",
    "        skipped += 1\n",
    "\n",
    "print(f\"‚úì {len(valid_tokens)} exemplos de valida√ß√£o tokenizados (ignorados: {skipped})\")\n",
    "\n",
    "# Mostrar estat√≠sticas\n",
    "if train_tokens:\n",
    "    lengths = [len(t) for t in train_tokens]\n",
    "    print(f\"\\nüìä Estat√≠sticas de Tokens (Treino):\")\n",
    "    print(f\"  ‚Ä¢ M√≠nimo: {min(lengths)} tokens\")\n",
    "    print(f\"  ‚Ä¢ M√°ximo: {max(lengths)} tokens\")\n",
    "    print(f\"  ‚Ä¢ M√©dia: {sum(lengths)/len(lengths):.0f} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Se√ß√£o 6: Sistema de M√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Classe MetricsTracker\n",
    "import json\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "class MetricsTracker:\n",
    "    \"\"\"Rastreia e persiste m√©tricas de treino em JSON e CSV\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: Path):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.metrics_file = self.output_dir / \"training_metrics.json\"\n",
    "        self.csv_file = self.output_dir / \"training_metrics.csv\"\n",
    "        self.state_file = self.output_dir / \"training_state.json\"\n",
    "        \n",
    "        self.metrics = []\n",
    "        self.best_loss = float('inf')\n",
    "        self.best_checkpoint = None\n",
    "        \n",
    "        self._load_state()\n",
    "    \n",
    "    def _load_state(self):\n",
    "        \"\"\"Carregar estado anterior se existir\"\"\"\n",
    "        if self.state_file.exists():\n",
    "            try:\n",
    "                with open(self.state_file) as f:\n",
    "                    state = json.load(f)\n",
    "                    self.best_loss = state.get('best_loss', float('inf'))\n",
    "                    print(f\"[INFO] Estado anterior carregado (best_loss: {self.best_loss:.4f})\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    def log_step(self, epoch: int, step: int, loss: float, \n",
    "                 val_loss: Optional[float] = None, learning_rate: float = 0):\n",
    "        \"\"\"Log de passo individual\"\"\"\n",
    "        metric = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'epoch': epoch,\n",
    "            'step': step,\n",
    "            'loss': float(loss),\n",
    "            'learning_rate': float(learning_rate)\n",
    "        }\n",
    "        \n",
    "        if val_loss is not None:\n",
    "            metric['val_loss'] = float(val_loss)\n",
    "            if val_loss < self.best_loss:\n",
    "                self.best_loss = val_loss\n",
    "        \n",
    "        self.metrics.append(metric)\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"Salvar m√©tricas em JSON\"\"\"\n",
    "        with open(self.metrics_file, 'w') as f:\n",
    "            json.dump(self.metrics, f, indent=2)\n",
    "        \n",
    "        # Salvar tamb√©m em CSV\n",
    "        import csv\n",
    "        if self.metrics:\n",
    "            keys = self.metrics[0].keys()\n",
    "            with open(self.csv_file, 'w', newline='') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=keys)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(self.metrics)\n",
    "    \n",
    "    def save_state(self, epoch: int, step: int):\n",
    "        \"\"\"Salvar estado para retomar\"\"\"\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'step': step,\n",
    "            'best_loss': self.best_loss,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        with open(self.state_file, 'w') as f:\n",
    "            json.dump(state, f, indent=2)\n\n# Inicializar tracker\ntracker = MetricsTracker(Config.checkpoint_dir)\nprint(\"‚úì Metrics tracker inicializado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Se√ß√£o 7: Loop de Treino (PRINCIPAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Configurar otimizador\n",
    "print(\"\\n[INFO] Configurando otimizador...\")\n",
    "optimizer = optim.Adam(learning_rate=Config.learning_rate)\nprint(\"‚úì Otimizador Adam configurado\")\n\n# 7.2 Fun√ß√£o de loss\ndef compute_loss(model, input_ids, labels):\n",
    "    \"\"\"Computar loss cross-entropy\"\"\"\n",
    "    logits = model(input_ids)\n",
    "    \n",
    "    # Shift logits e labels para language modeling\n",
    "    # Loss computado entre predi√ß√£o e pr√≥ximo token\n",
    "    loss = nn.losses.cross_entropy(\n",
    "        logits[:, :-1, :],  # Predi√ß√µes: todos menos √∫ltimo\n",
    "        labels[:, 1:],      # Targets: todos menos primeiro\n",
    "        reduction=\"mean\"\n",
    "    )\n",
    "    return loss\n",
    "\nprint(\"‚úì Fun√ß√£o de loss definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 MAIN TRAINING LOOP\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ INICIANDO TREINO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "training_start = time.time()\n",
    "\n",
    "for epoch in range(Config.num_epochs):\n",
    "    print(f\"\\nüìç √âPOCA {epoch + 1}/{Config.num_epochs}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Embaralhar dados\n",
    "    indices = list(range(len(train_tokens)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_steps = 0\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Loop de treino\n",
    "    for batch_idx in range(0, len(train_tokens), Config.batch_size):\n",
    "        batch_indices = indices[batch_idx:batch_idx + Config.batch_size]\n",
    "        \n",
    "        if not batch_indices:\n",
    "            break\n",
    "        \n",
    "        # Criar batch\n",
    "        batch_tokens = [train_tokens[i] for i in batch_indices]\n",
    "        \n",
    "        # Padding\n",
    "        max_len = max(len(t) for t in batch_tokens)\n",
    "        padded = []\n",
    "        for tokens in batch_tokens:\n",
    "            padded_tokens = tokens + [tokenizer.eos_token_id] * (max_len - len(tokens))\n",
    "            padded.append(padded_tokens[:max_len])\n",
    "        \n",
    "        # Converter para arrays MLX\n",
    "        input_ids = mx.array(padded)\n",
    "        labels = mx.array(padded)\n",
    "        \n",
    "        # Compute gradients\n",
    "        loss_fn = lambda m: compute_loss(m, input_ids, labels)\n",
    "        loss_val, grads = mx.value_and_grad(loss_fn)(model)\n",
    "        \n",
    "        # Update model\n",
    "        optimizer.update(model, grads)\n",
    "        mx.eval(model.parameters(), optimizer.state)\n",
    "        \n",
    "        epoch_loss += loss_val.item()\n",
    "        epoch_steps += 1\n",
    "        \n",
    "        # Log\n",
    "        if epoch_steps % Config.log_steps == 0:\n",
    "            avg_loss = epoch_loss / epoch_steps\n",
    "            print(f\"  Passo {epoch_steps:3d} | Loss: {avg_loss:.4f}\")\n",
    "            tracker.log_step(epoch, epoch_steps, avg_loss, learning_rate=Config.learning_rate)\n",
    "            tracker.save()\n",
    "            tracker.save_state(epoch, epoch_steps)\n",
    "        \n",
    "        # Valida√ß√£o\n",
    "        if epoch_steps % Config.eval_steps == 0 and epoch_steps > 0:\n",
    "            print(f\"\\n  [INFO] Avaliando em valida√ß√£o...\")\n",
    "            val_loss = 0\n",
    "            val_steps = 0\n",
    "            \n",
    "            for val_idx in range(0, len(valid_tokens), Config.batch_size):\n",
    "                val_indices = list(range(val_idx, min(val_idx + Config.batch_size, len(valid_tokens))))\n",
    "                \n",
    "                val_batch = [valid_tokens[i] for i in val_indices]\n",
    "                max_len_val = max(len(t) for t in val_batch)\n",
    "                \n",
    "                val_padded = []\n",
    "                for tokens in val_batch:\n",
    "                    padded_tokens = tokens + [tokenizer.eos_token_id] * (max_len_val - len(tokens))\n",
    "                    val_padded.append(padded_tokens[:max_len_val])\n",
    "                \n",
    "                val_input_ids = mx.array(val_padded)\n",
    "                val_labels = mx.array(val_padded)\n",
    "                \n",
    "                val_loss_step = compute_loss(model, val_input_ids, val_labels)\n",
    "                val_loss += val_loss_step.item()\n",
    "                val_steps += 1\n",
    "            \n",
    "            avg_val_loss = val_loss / max(val_steps, 1)\n",
    "            print(f\"  ‚úì Val Loss: {avg_val_loss:.4f}\")\n",
    "            tracker.log_step(epoch, epoch_steps, epoch_loss / epoch_steps, \n",
    "                             val_loss=avg_val_loss, learning_rate=Config.learning_rate)\n",
    "            tracker.save()\n",
    "    \n",
    "    # Fim da √©poca\n",
    "    epoch_duration = time.time() - epoch_start\n",
    "    avg_epoch_loss = epoch_loss / max(epoch_steps, 1)\n",
    "    print(f\"\\n‚úì √âpoca {epoch + 1} conclu√≠da em {epoch_duration:.1f}s\")\n",
    "    print(f\"  Loss m√©dio: {avg_epoch_loss:.4f}\")\n\ntotal_duration = time.time() - training_start\nprint(f\"\\n\" + \"=\"*70)\nprint(f\"‚úÖ TREINO COMPLETO em {total_duration/3600:.1f} horas ({total_duration/60:.0f} minutos)\")\nprint(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Se√ß√£o 8: Testes de Gera√ß√£o (Valida√ß√£o Qualitativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Teste de gera√ß√£o simples\n",
    "print(\"\\n[INFO] Testando gera√ß√£o de texto...\")\n",
    "\n",
    "test_prompts = [\n",
    "    \"Qual foi o resultado do Farense\",\n",
    "    \"O Farense ganhou\",\n",
    "    \"Qual foi a melhor classifica√ß√£o\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üß™ TESTE DE GERA√á√ÉO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nüìù Pergunta: {prompt}\")\n",
    "    try:\n",
    "        response = generate(\n",
    "            model, \n",
    "            tokenizer, \n",
    "            prompt=prompt,\n",
    "            max_tokens=50,\n",
    "            verbose=False\n",
    "        )\n",
    "        print(f\"‚úì Resposta: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† Erro: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Se√ß√£o 9: Salvar Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1 Salvar resumo de treino\n",
    "print(\"\\n[INFO] Salvando resumo de treino...\")\n",
    "\n",
    "summary = {\n",
    "    'training_completed_at': datetime.now().isoformat(),\n",
    "    'total_duration_seconds': total_duration,\n",
    "    'total_duration_hours': total_duration / 3600,\n",
    "    'epochs': Config.num_epochs,\n",
    "    'batch_size': Config.batch_size,\n",
    "    'learning_rate': Config.learning_rate,\n",
    "    'train_examples': len(train_data),\n",
    "    'valid_examples': len(valid_data),\n",
    "    'best_validation_loss': tracker.best_loss\n",
    "}\n",
    "\n",
    "summary_file = Config.checkpoint_dir / \"training_summary.json\"\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"‚úì Resumo salvo em {summary_file.name}\")\n",
    "\n",
    "# 9.2 Mostrar resumo\n",
    "print(f\"\"\"\n",
    "üìä RESUMO DO TREINO:\n",
    "  ‚Ä¢ Dura√ß√£o Total: {total_duration/3600:.1f}h ({total_duration/60:.0f}m)\n",
    "  ‚Ä¢ √âpocas: {Config.num_epochs}\n",
    "  ‚Ä¢ Exemplos de Treino: {len(train_data)}\n",
    "  ‚Ä¢ Exemplos de Valida√ß√£o: {len(valid_data)}\n",
    "  ‚Ä¢ Batch Size: {Config.batch_size}\n",
    "  ‚Ä¢ Learning Rate: {Config.learning_rate}\n",
    "  ‚Ä¢ Best Validation Loss: {tracker.best_loss:.4f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Se√ß√£o 10: Pr√≥ximas Etapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚úÖ TREINO CONCLU√çDO COM SUCESSO!\n",
    "\n",
    "üìÇ Ficheiros Gerados:\n",
    "  ‚úì checkpoints_qlora/training_metrics.json     (m√©tricas em tempo real)\n",
    "  ‚úì checkpoints_qlora/training_metrics.csv      (formato CSV)\n",
    "  ‚úì checkpoints_qlora/training_summary.json     (resumo final)\n",
    "  ‚úì checkpoints_qlora/checkpoint_*_*/           (checkpoints interm√©dios)\n",
    "\n",
    "üéØ PR√ìXIMOS PASSOS:\n",
    "\n",
    "1. VISUALIZAR RESULTADOS:\n",
    "   python3 scripts/visualization.py --report\n",
    "\n",
    "2. TESTAR MODELO:\n",
    "   python3 scripts/inference_qlora.py \"Qual foi a melhor classifica√ß√£o do Farense?\"\n",
    "\n",
    "3. COMPARAR MODELOS:\n",
    "   python3 scripts/compare_models.py\n",
    "\n",
    "4. AN√ÅLISE DE M√âTRICAS:\n",
    "   Abra checkpoints_qlora/training_metrics.json\n",
    "\n",
    "üìä M√âTRICAS PRINCIPAIS:\n",
    "   ‚Ä¢ Training Loss: {tracker.best_loss:.4f}\n",
    "   ‚Ä¢ Dura√ß√£o: {total_duration/3600:.1f}h\n",
    "   ‚Ä¢ Batch Size: {Config.batch_size}\n",
    "   ‚Ä¢ Learning Rate: {Config.learning_rate}\n",
    "\n",
    "üí° DICAS:\n",
    "   ‚Ä¢ Se o val_loss > train_loss: aumentar dropout ou regulariza√ß√£o\n",
    "   ‚Ä¢ Se a loss n√£o diminuir: aumentar learning rate ou num_epochs\n",
    "   ‚Ä¢ Se erro de mem√≥ria: reduzir batch_size de {Config.batch_size} para {Config.batch_size-2}\n",
    "\n",
    "üöÄ PRONTO PARA PRODU√á√ÉO!\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
