# Sistema de MonitorizaÃ§Ã£o de Treinamento

Guia completo para monitorizar o seu treinamento com mÃ©tricas, grÃ¡ficos e dashboard em tempo real.

## ðŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Componentes do Sistema](#componentes-do-sistema)
3. [Como Usar](#como-usar)
4. [Exemplos PrÃ¡ticos](#exemplos-prÃ¡ticos)
5. [Interpretando Resultados](#interpretando-resultados)
6. [Troubleshooting](#troubleshooting)

---

## ðŸŽ¯ VisÃ£o Geral

O sistema de monitorizaÃ§Ã£o fornece:

| Componente | DescriÃ§Ã£o | Output |
|---|---|---|
| **MetricsTracker** | Captura todas as mÃ©tricas de treinamento | CSV + JSON |
| **PerformanceMonitor** | Rastreia uso de memÃ³ria | Stats integradas |
| **TrainingVisualizer** | Cria grÃ¡ficos e dashboards | PNG + RelatÃ³rios |
| **Monitor CLI** | Monitor em tempo real no terminal | Live updates |

---

## ðŸ”§ Componentes do Sistema

### 1. MetricsTracker (`scripts/metrics.py`)

Rastreia e persiste todas as mÃ©tricas durante o treinamento.

**FunÃ§Ãµes principais:**

```python
tracker = MetricsTracker(output_dir='checkpoints')

# Log de cada step
tracker.log_step(
    epoch=0,
    step=100,
    loss=2.345,
    val_loss=2.456,
    learning_rate=1e-5,
    memory_mb=9000,
    elapsed_time=120
)

# Log de fim de Ã©poca
tracker.log_epoch(
    epoch=0,
    avg_loss=2.345,
    val_loss=2.456,
    elapsed_time=3600
)

# Salvar sumÃ¡rio final
tracker.save_summary(
    total_time=7200,
    total_samples=2414,
    training_config={'lr': 1e-5}
)

# Ver status
tracker.print_status()
```

**Output:**
- `training_metrics.csv` - Todas as mÃ©tricas por linha
- `training_metrics.json` - Dados estruturados
- `training_summary.json` - SumÃ¡rio final com estatÃ­sticas

### 2. PerformanceMonitor

Monitora performance do sistema:

```python
monitor = PerformanceMonitor()
monitor.record_memory(available_mb=9500)
stats = monitor.get_stats()
```

### 3. TrainingVisualizer (`scripts/visualization.py`)

Cria visualizaÃ§Ãµes dos dados:

```python
viz = TrainingVisualizer(output_dir='checkpoints')

# GrÃ¡fico de loss
viz.plot_loss_curves(save=True)

# Uso de memÃ³ria
viz.plot_memory_usage(save=True)

# Dashboard completo
viz.create_dashboard(save=True)

# RelatÃ³rio formatado
viz.print_training_report()
```

**Output:**
- `checkpoints/plots/loss_curves.png` - Curva de loss treino vs validaÃ§Ã£o
- `checkpoints/plots/memory_usage.png` - GrÃ¡fico de memÃ³ria
- `checkpoints/plots/dashboard.png` - Dashboard consolidado

### 4. Monitor CLI (`scripts/monitor.py`)

Monitor em tempo real:

```bash
# Monitor contÃ­nuo
python scripts/monitor.py

# Monitor com intervalo customizado
python scripts/monitor.py --refresh 10

# Gerar relatÃ³rio final
python scripts/monitor.py --report

# Monitor diretÃ³rio especÃ­fico
python scripts/monitor.py --output-dir ./my_checkpoints
```

---

## ðŸ“– Como Usar

### OpÃ§Ã£o 1: Usar o Notebook Monitorizado

**Arquivo:** `notebooks/mistral_qlora_training_monitored.ipynb`

1. Abrir no Jupyter
2. Executar cÃ©lulas sequencialmente
3. MonitorizaÃ§Ã£o automÃ¡tica integrada
4. GrÃ¡ficos e relatÃ³rios ao final

### OpÃ§Ã£o 2: Integrar no Seu CÃ³digo Atual

No seu script de treinamento:

```python
from scripts.metrics import MetricsTracker, PerformanceMonitor

# Inicializar
tracker = MetricsTracker('checkpoints')
monitor = PerformanceMonitor()

# Durante treinamento
for epoch in range(num_epochs):
    for step, batch in enumerate(train_loader):
        # ... seu cÃ³digo de treinamento ...

        # Log a cada N steps
        if step % 50 == 0:
            tracker.log_step(
                epoch=epoch,
                step=step,
                loss=loss_value,
                memory_mb=get_available_memory(),
                elapsed_time=time.time() - start_time
            )

    # Log ao fim da Ã©poca
    tracker.log_epoch(
        epoch=epoch,
        avg_loss=avg_loss,
        val_loss=val_loss_value,
        elapsed_time=time.time() - start_time
    )

    # Salvar checkpoint de mÃ©tricas
    tracker.save_json()

# Final
summary = tracker.save_summary(
    total_time=time.time() - start_time,
    total_samples=len(dataset),
    training_config=config
)
```

### OpÃ§Ã£o 3: Monitorar Treinamento Existente

Enquanto o notebook estÃ¡ a correr em outro terminal:

```bash
# Terminal 1: Executar treinamento
jupyter notebook

# Terminal 2: Monitorar em tempo real
python scripts/monitor.py

# Terminal 3: Gerar relatÃ³rio final
python scripts/monitor.py --report
```

---

## ðŸ’¡ Exemplos PrÃ¡ticos

### Exemplo 1: Verificar Progresso Atual

```bash
# Num terminal diferente
python scripts/monitor.py --refresh 5
```

Output:
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    TRAINING MONITOR - 2025-11-09 14:30:45                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“Š CURRENT STATUS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Epoch: 2  |  Step: 450  |  Elapsed: 2.3h
  Current Loss: 1.2345  |  Best Loss: 0.9876
  Memory Available: 8500MB

ðŸ“ˆ LOSS STATISTICS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Steps with data: 450
  Loss range: 0.9876 - 4.5678
  Improvement: 3.2345 (+65.3%)

ðŸŽ¯ VALIDATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Best Val Loss: 1.0234
  Latest Val Loss: 1.0456

ðŸ† BEST CHECKPOINT
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Epoch: 1
  Step: 250
  Loss: 0.9876
```

### Exemplo 2: Gerar GrÃ¡ficos ao Final

```python
from scripts.visualization import TrainingVisualizer

viz = TrainingVisualizer('checkpoints')
viz.plot_loss_curves(save=True)
viz.plot_memory_usage(save=True)
viz.create_dashboard(save=True)
viz.print_training_report()
```

Output:
```
======================================================================
                     TRAINING REPORT
======================================================================

ðŸ“Š TIMING
  Total Time: 2.35 hours (8460s)
  Samples/second: 285.24

ðŸ“ˆ ITERATIONS
  Total Steps: 2414
  Total Epochs: 3
  Total Samples: 2414

ðŸ“‰ LOSS METRICS
  Best Train Loss: 0.9876
  Final Train Loss: 1.0234
  Loss Improvement: 3.2345 (65.3%)
  Best Val Loss: 0.9654
  Final Val Loss: 1.0456

ðŸŽ¯ BEST CHECKPOINT
  Epoch: 1
  Step: 250
  Loss: 0.9876

âš™ï¸  CONFIGURATION
  num_epochs: 3
  batch_size: 1
  learning_rate: 0.00001
  max_seq_length: 256
```

### Exemplo 3: Ler MÃ©tricas Programaticamente

```python
import json

# Ler CSV
import pandas as pd
df = pd.read_csv('checkpoints/training_metrics.csv')
print(df.tail())

# Ler JSON
with open('checkpoints/training_metrics.json') as f:
    metrics = json.load(f)

# Acessar dados
best_loss = metrics['best_loss']
total_steps = metrics['total_steps']
step_metrics = metrics['step_metrics']

# AnÃ¡lise
print(f"Best loss: {best_loss}")
print(f"Total steps: {total_steps}")
print(f"Loss history: {[m['loss'] for m in step_metrics[-10:]]}")
```

---

## ðŸ“Š Interpretando Resultados

### Loss Curves

```
Comportamento Esperado:
- Loss diminui ao longo dos steps (treino aprendendo)
- ValidaÃ§Ã£o segue similar ao treino
- Ambas convergem gradualmente

Problemas Comuns:
- Loss constante â†’ Taxa de aprendizado muito baixa
- Loss sobe â†’ Taxa de aprendizado muito alta
- Val loss sobe, train desce â†’ Overfitting
- Picos aleatÃ³rios â†’ Dados problemÃ¡ticos
```

### Memory Usage

```
Esperado:
- MemÃ³ria estÃ¡vel durante treino
- Pequenas variaÃ§Ãµes normais
- Nunca deve cair abaixo de 1GB

Problemas:
- MemÃ³ria diminuindo â†’ Memory leak
- Crash em memÃ³ria â†’ Aumentar gradient accumulation
- VariaÃ§Ãµes grandes â†’ Problemas de batch size
```

### MÃ©tricas Chave

| MÃ©trica | Valor Bom | Valor ProblemÃ¡tico |
|---------|-----------|-------------------|
| Loss Improvement | >50% | <10% |
| Validation vs Train | Similar | Val >> Train (overfitting) |
| Samples/second | >100 | <50 (lento) |
| Memory Stable | Sim | Trending down |

---

## ðŸ” Troubleshooting

### Problema: Nenhuma mÃ©trica registada

**SoluÃ§Ã£o:**
1. Verificar se `checkpoints/` existe
2. Confirmar que o treinamento comeÃ§ou
3. Ver se hÃ¡ erros no notebook

```bash
ls -la checkpoints/
cat checkpoints/training_metrics.csv
```

### Problema: GrÃ¡ficos nÃ£o aparecem

**SoluÃ§Ã£o:**
1. Instalar matplotlib
2. Usar `%matplotlib inline` no Jupyter

```bash
pip install matplotlib
```

No notebook:
```python
%matplotlib inline
```

### Problema: Memory leak aparente

**SoluÃ§Ã£o:**
1. Adicionar `gc.collect()` no loop
2. Aumentar `gradient_accumulation_steps`
3. Diminuir batch size

### Problema: Loss nÃ£o melhora

**PossÃ­veis causas:**
- Learning rate muito alto (loss salta)
- Learning rate muito baixo (loss estagnada)
- Dados de qualidade inferior
- Modelo jÃ¡ convergiu

**SoluÃ§Ãµes:**
- Tente learning rate = 1e-4 ou 1e-6
- Verificar qualidade dos dados
- Aumentar nÃºmero de Ã©pocas

---

## ðŸ“ Estrutura de Ficheiros

```
checkpoints/
â”œâ”€â”€ training_metrics.csv          â† Todas as mÃ©tricas em CSV
â”œâ”€â”€ training_metrics.json         â† MÃ©tricas em JSON
â”œâ”€â”€ training_summary.json         â† SumÃ¡rio final
â””â”€â”€ plots/
    â”œâ”€â”€ loss_curves.png          â† GrÃ¡fico de loss
    â”œâ”€â”€ memory_usage.png         â† GrÃ¡fico de memÃ³ria
    â””â”€â”€ dashboard.png            â† Dashboard completo
```

---

## ðŸš€ Quick Start

**3 passos para comeÃ§ar:**

1. **Abrir notebook monitorizado:**
   ```bash
   jupyter notebook notebooks/mistral_qlora_training_monitored.ipynb
   ```

2. **Em outro terminal, monitorar:**
   ```bash
   python scripts/monitor.py --refresh 5
   ```

3. **Ao final, gerar relatÃ³rios:**
   ```bash
   python scripts/monitor.py --report
   ```

---

## ðŸ“ž Perguntas Frequentes

**P: Como saber se o treinamento estÃ¡ funcionando?**
R: Veja se a loss estÃ¡ a descer consistentemente e os checkpoints estÃ£o a ser criados.

**P: Quanto tempo leva o treinamento?**
R: Estimado no monitor, tipicamente 2-3 horas para 3 Ã©pocas num Mac M1.

**P: Posso parar e retomar?**
R: Sim! O sistema salva checkpoints e pode retomar de onde parou.

**P: Como optimizar a velocidade?**
R: Aumentar `gradient_accumulation_steps` ou reduzir `max_seq_length`.

---

## ðŸ“ Resumo de Comandos

```bash
# Monitorar em tempo real
python scripts/monitor.py

# Gerar grÃ¡ficos finais
python scripts/monitor.py --report

# Ler CSV com pandas
python -c "import pandas as pd; print(pd.read_csv('checkpoints/training_metrics.csv').tail())"

# Ver resumo JSON
cat checkpoints/training_summary.json | jq '.'

# Ver status
python -c "from scripts.metrics import MetricsTracker; MetricsTracker('checkpoints').print_status()"
```

---

Boa sorte com o seu treinamento! ðŸš€
