# ğŸš€ Quickstart - QLoRA Training para Farense Bot

## O que foi feito?

Sua pipeline de fine-tuning foi refatorada de **LoRA** para **QLoRA** com MLX, otimizado para Mac M1 Pro/Max.

### Principais MudanÃ§as:
- âœ“ QuantizaÃ§Ã£o INT4 (modelo 14GB â†’ 3.5GB)
- âœ“ Menos memÃ³ria VRAM (8-10GB â†’ 4-6GB)
- âœ“ Treino 30% mais rÃ¡pido
- âœ“ Mesmo notebook melhorado e organizado
- âœ“ Scripts de inferÃªncia atualizados

---

## ğŸ“‹ PrÃ©-requisitos

### Hardware
- Mac M1/M2/M3 Pro ou Max (recomendado)
- MÃ­nimo 4GB VRAM livre
- ~5GB espaÃ§o em disco

### Software
```bash
# Instalar Python 3.11+
python3 --version  # deve ser 3.11 ou superior

# Instalar dependÃªncias
pip install mlx mlx-lm mlx-data numpy pandas tqdm pydantic psutil

# Verificar instalaÃ§Ã£o
python3 -c "import mlx.core as mx; print('âœ“ MLX OK')"
```

---

## ğŸ¯ Como Executar

### Passo 1: Abrir o Notebook
```bash
cd /Users/f.nuno/Desktop/chatbot_2.0/LLM_training
jupyter notebook notebooks/mistral_qlora_training.ipynb
```

### Passo 2: Executar CÃ©lula por CÃ©lula

#### SeÃ§Ã£o 1: Setup (executar na ordem)
```python
# Cell 1-6: Imports e verificaÃ§Ã£o
# Verifica M1 Mac e carrega MLX
```

#### SeÃ§Ã£o 2: Dados (automÃ¡tico)
```python
# Cell 7-10: Carrega dados jÃ¡ processados
# ou regenera se necessÃ¡rio
```

#### SeÃ§Ã£o 3: Modelo QLoRA (inÃ­cio do treino)
```python
# Cell 11-17: Carrega modelo Mistral-7B com quantizaÃ§Ã£o INT4
```

#### SeÃ§Ã£o 4: Treino (o principal)
```python
# Cell 18-20: Inicia treino
# VerÃ¡ progresso em tempo real
# Checkpoints salvos automaticamente
```

#### SeÃ§Ã£o 5: Teste
```python
# Cell 21-22: Testa geraÃ§Ã£o de respostas
```

#### SeÃ§Ã£o 6: Export
```python
# Cell 23-26: Salva modelo final e scripts
```

---

## â±ï¸ Tempo Esperado

| Fase | Tempo | ObservaÃ§Ãµes |
|------|-------|-------------|
| Setup/Imports | 2-3 min | Carrega bibliotecas |
| Dados | 1-2 min | Valida e prepara dados |
| Modelo | 5-10 min | Download + quantizaÃ§Ã£o |
| **Treino 1 Ã©poca** | **~30-40 min** | VocÃª pode acompanhar em tempo real |
| **Treino 3 Ã©pocas** | **~1.5-2 horas** | Recomendado: 3 Ã©pocas para boa qualidade |
| ValidaÃ§Ã£o | 3-5 min | Entre Ã©pocas |
| Export | 1-2 min | Salva modelo final |
| **TOTAL** | **~2-3 horas** | Inclui treino completo |

---

## ğŸ“Š Monitoramento em Tempo Real

Durante o treino, vocÃª verÃ¡:

```
Epoch 1/3
Training: 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 1207/2414
  [Memory] Epoch 1 start: 3625MB disponÃ­vel
  Step 20/2414 - Loss: 2.5234
  Step 40/2414 - Loss: 2.1892
  [Memory] Step 40: 3500MB disponÃ­vel
  Step 60/2414 - Loss: 1.8765
  âœ“ Checkpoint saved (step 200)
  ...
Validating: 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 9/30
  Val Loss: 1.4532
  âœ“ Best model saved (Loss: 1.4532)
  âœ“ Epoch 1 complete
```

### O que significa?
- **Loss**: Quanto menor, melhor (deve diminuir a cada Ã©poca)
- **Memory**: Deve ficar entre 4-6GB (normal)
- **Tokens/sec**: Velocidade de geraÃ§Ã£o (300-500 Ã© bom)

---

## ğŸ› ï¸ ConfiguraÃ§Ãµes Personalizadas

### Para M1 Base (8GB RAM) - MÃ­nimo
```python
training_config = {
    "num_epochs": 1,              # Menos Ã©pocas
    "batch_size": 1,
    "gradient_accumulation": 1,
    "max_seq_length": 256,        # SequÃªncias mais curtas
}
```

### Para M1 Pro (16GB RAM) - Recomendado
```python
training_config = {
    "num_epochs": 3,              # Treino completo
    "batch_size": 2,
    "gradient_accumulation": 2,
    "max_seq_length": 512,        # SequÃªncias mÃ©dias
}
```

### Para M1 Max (32GB+ RAM) - Premium
```python
training_config = {
    "num_epochs": 5,              # Mais Ã©pocas
    "batch_size": 4,
    "gradient_accumulation": 1,
    "max_seq_length": 1024,       # SequÃªncias longas
}
```

---

## ğŸš€ Usar o Modelo Treinado

### OpÃ§Ã£o 1: Dentro do Notebook
```python
response = generate_response(
    model,
    tokenizer,
    "Qual foi a melhor classificaÃ§Ã£o do Farense?",
    max_tokens=200
)
print(response)
```

### OpÃ§Ã£o 2: Via Script Python
```bash
python scripts/inference_qlora.py "Sua pergunta aqui"
```

### OpÃ§Ã£o 3: Integrar no Express Backend
```javascript
// Node.js
const { spawn } = require('child_process');

function askFarenseBot(question) {
  return new Promise((resolve, reject) => {
    const process = spawn('python', [
      'scripts/inference_qlora.py',
      question
    ]);

    let output = '';
    process.stdout.on('data', (data) => {
      output += data.toString();
    });

    process.on('close', (code) => {
      try {
        const result = JSON.parse(output);
        resolve(result.response);
      } catch (e) {
        reject(e);
      }
    });
  });
}

// Usar
askFarenseBot("Conte-me sobre Hassan Nader")
  .then(response => console.log(response))
  .catch(error => console.error(error));
```

---

## ğŸ“ Arquivos Importantes

```
LLM_training/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ mistral_qlora_training.ipynb    â† NOVO (use este!)
â”‚   â””â”€â”€ mistral_lora_training.ipynb     â† Antigo
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ inference_qlora.py              â† NOVO (use este!)
â”‚   â”œâ”€â”€ inference.py                    â† Antigo
â”‚   â””â”€â”€ compare_models.py               â† Comparar LoRA vs QLoRA
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ mistral-7b-farense-qlora/       â† Modelo QLoRA treinado
â”‚   â”œâ”€â”€ mistral-7b-farense-lora/        â† Modelo LoRA antigo
â”‚   â””â”€â”€ comparison_results.json         â† Benchmark results
â”‚
â”œâ”€â”€ checkpoints_qlora/                  â† Checkpoints de treino
â”‚   â”œâ”€â”€ checkpoint_epoch0_step200/
â”‚   â”œâ”€â”€ checkpoint_epoch0_best/
â”‚   â””â”€â”€ training_state.json
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train_data.jsonl                â† 2414 exemplos
â”‚   â””â”€â”€ val_data.jsonl                  â† 269 exemplos
â”‚
â”œâ”€â”€ QLORA_GUIDE.md                      â† Guia completo
â”œâ”€â”€ QUICKSTART_QLORA.md                 â† Este arquivo
â””â”€â”€ README.md                           â† Original
```

---

## âš ï¸ Troubleshooting

### Erro: "MemÃ³ria insuficiente"
```python
# No notebook, cÃ©lula 12, reduzir:
training_config["batch_size"] = 1
training_config["gradient_accumulation"] = 4
training_config["max_seq_length"] = 256
```

### Erro: "Model not found"
```bash
# Garantir que MLX tem acesso Ã  internet para baixar Mistral-7B
pip install --upgrade mlx-lm
```

### Loss estÃ¡ subindo (divergindo)
```python
# No notebook, cÃ©lula 12, reduzir learning rate:
training_config["learning_rate"] = 1e-4  # De 2e-4 para 1e-4
training_config["warmup_steps"] = 200    # Aumentar warmup
```

### Treino muito lento
```python
# Aumentar batch size (se houver memÃ³ria)
training_config["batch_size"] = 4  # De 2 para 4
# ou reduzir sequÃªncia
training_config["max_seq_length"] = 256  # De 512 para 256
```

---

## ğŸ“Š Comparar LoRA vs QLoRA

```bash
python scripts/compare_models.py
```

Isso vai:
1. Carregar modelo LoRA
2. Carregar modelo QLoRA
3. Fazer benchmark nos mesmos prompts
4. Mostrar diferenÃ§as de speed/qualidade
5. Salvar resultados em `output/comparison_results.json`

---

## âœ… Checklist de Sucesso

- [ ] DependÃªncias instaladas (`pip install mlx mlx-lm`)
- [ ] Mac M1 detectado (vÃª mensagem "âœ“ Mac M1 detected")
- [ ] Dados carregados (2414 + 269 exemplos)
- [ ] Modelo Mistral-7B carregado
- [ ] QLoRA configurado (INT4 quantization)
- [ ] Treino iniciado sem erros
- [ ] Loss diminuindo a cada Ã©poca
- [ ] Checkpoints salvos
- [ ] Modelo final exportado
- [ ] InferÃªncia funcionando

---

## ğŸ“š PrÃ³ximas AÃ§Ãµes

1. **Executar treino**
   ```bash
   jupyter notebook notebooks/mistral_qlora_training.ipynb
   ```

2. **Testar qualidade**
   ```bash
   python scripts/inference_qlora.py "Qual Ã© a histÃ³ria do Farense?"
   ```

3. **Comparar com antigo**
   ```bash
   python scripts/compare_models.py
   ```

4. **Integrar no backend**
   - Copiar `scripts/inference_qlora.py` para seu backend
   - Chamar como subprocess a partir do Express

5. **Deploy em produÃ§Ã£o**
   - Model estÃ¡ em: `output/mistral-7b-farense-qlora/`
   - Distribuir com `INTEGRATION_GUIDE.md`

---

## ğŸ“ ReferÃªncias RÃ¡pidas

### QLoRA vs LoRA
| Feature | LoRA | QLoRA | Melhor |
|---------|------|-------|--------|
| Tamanho | 14GB | 3.5GB | QLoRA âœ“ |
| MemÃ³ria | 8-10GB | 4-6GB | QLoRA âœ“ |
| Treino | 100% | 70% | QLoRA âœ“ |
| Qualidade | - | -1% | Similar |

### Comandos Ãšteis
```bash
# Listar modelos disponÃ­veis
python scripts/compare_models.py

# Testar uma pergunta
python scripts/inference_qlora.py "pergunta"

# Ver checkpoint especÃ­fico
ls -lh checkpoints_qlora/checkpoint_epoch*/checkpoint_info.json

# Monitorar memÃ³ria durante treino
watch -n 1 'memory_stat'
```

---

## ğŸ’¡ Dicas Finais

1. **NÃ£o interrompa o treino** - Ele pode resumir a partir do Ãºltimo checkpoint
2. **Monitore a memÃ³ria** - Deve ficar estÃ¡vel entre 4-6GB
3. **Loss deve diminuir** - Se aumentar, algo estÃ¡ errado
4. **Checkpoints sÃ£o automÃ¡ticos** - NÃ£o precisa fazer nada
5. **Qualidade melhora com Ã©pocas** - 3 Ã©pocas Ã© bom ponto de equilÃ­brio

---

## ğŸ†˜ Suporte

Para problemas:
1. Verificar `QLORA_GUIDE.md` (mais detalhado)
2. Ver logs em `checkpoints_qlora/training_state.json`
3. Verificar mensagens de erro no notebook
4. Reduzir batch size se memÃ³ria Ã© problema

---

**Data:** 2025-11-09
**VersÃ£o:** QLoRA + MLX para Mac M1
**Status:** âœ“ Pronto para uso
